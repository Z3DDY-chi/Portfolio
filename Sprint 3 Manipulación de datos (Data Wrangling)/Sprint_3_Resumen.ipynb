{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a3996f0",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: DataFrames en la librer√≠a Pandas\n",
    "\n",
    "Este cap√≠tulo introduce los conceptos fundamentales de pandas y DataFrames, herramientas esenciales para el an√°lisis y manipulaci√≥n de datos en Python. Se enfoca en:\n",
    "\n",
    "- Comprensi√≥n de la librer√≠a pandas\n",
    "    - Entender pandas como la librer√≠a m√°s utilizada para procesamiento de datos, superior a hojas de c√°lculo para grandes vol√∫menes de informaci√≥n\n",
    "- Importaci√≥n y alias de pandas\n",
    "    - Dominar la sintaxis est√°ndar para importar pandas usando el alias pd para facilitar su uso posterior\n",
    "- Estructura del DataFrame\n",
    "    - Comprender los DataFrames como estructuras bidimensionales similares a tablas con filas indexadas y columnas nombradas\n",
    "- Creaci√≥n de DataFrames\n",
    "    - Aplicar la clase DataFrame() para convertir listas anidadas en estructuras de datos organizadas\n",
    "- Argumentos data y columns\n",
    "    - Utilizar correctamente los par√°metros necesarios para construir DataFrames con datos y nombres de columnas\n",
    "- Documentaci√≥n de datos\n",
    "    - Interpretar la importancia de documentar columnas para comprender completamente la estructura y contenido de los datos\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "\n",
    "### Importaci√≥n de librer√≠a:\n",
    "- import pandas - Importa la librer√≠a pandas completa\n",
    "- import pandas as pd - Importa pandas con alias pd (pr√°ctica est√°ndar)\n",
    "\n",
    "### Creaci√≥n de DataFrame:\n",
    "- pd.DataFrame() - Clase para crear objetos DataFrame\n",
    "- data= - Par√°metro que acepta listas anidadas con los datos\n",
    "- columns= - Par√°metro que acepta lista con nombres de columnas\n",
    "\n",
    "### Funci√≥n de salida:\n",
    "- print() - Muestra el contenido del DataFrame creado\n",
    "\n",
    "### Estructuras de datos:\n",
    "- [ ] - Listas para almacenar datos y nombres de columnas\n",
    "- [[ ]] - Listas anidadas para representar filas de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62689881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Importaci√≥n est√°ndar:\n",
    "import pandas as pd\n",
    "\n",
    "# Preparaci√≥n de datos:\n",
    "atlas = [\n",
    "    ['France', 'Paris'],\n",
    "    ['Russia', 'Moscow'],\n",
    "    ['China', 'Beijing'],\n",
    "    ['Mexico', 'Mexico City'],\n",
    "    ['Egypt', 'Cairo']\n",
    "]\n",
    "geography = ['country', 'capital']\n",
    "\n",
    "# Creaci√≥n de DataFrame:\n",
    "world_map = pd.DataFrame(data=atlas, columns=geography)\n",
    "print(world_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9898de6f",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Librer√≠a pandas\n",
    "- Colecci√≥n de c√≥digo especializada en procesamiento y an√°lisis de datos, superior a hojas de c√°lculo para grandes vol√∫menes\n",
    "- DataFrame\n",
    "- Estructura de datos bidimensional similar a una tabla, donde cada elemento tiene coordenadas de fila y columna\n",
    "- √çndices\n",
    "- Identificadores num√©ricos que permiten acceder a las filas del DataFrame, comenzando desde 0\n",
    "- Columnas nombradas\n",
    "- Atributos que describen las caracter√≠sticas de las entidades almacenadas en cada fila del DataFrame\n",
    "- Clase DataFrame()\n",
    "- Plantilla para crear objetos DataFrame que requiere argumentos data y columns\n",
    "- Importaci√≥n con alias\n",
    "- Pr√°ctica est√°ndar de usar pd como abreviatura para acceder a las funcionalidades de pandas\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øPor qu√© crees que es importante convertir datos de listas anidadas a DataFrames antes de analizarlos? Piensa en las ventajas que podr√≠a ofrecer tener datos organizados en columnas con nombres espec√≠ficos versus trabajar directamente con listas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad6b46e",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Importaci√≥n y uso de paquetes\n",
    "\n",
    "Este cap√≠tulo introduce los conceptos fundamentales para comenzar a trabajar con la librer√≠a pandas, estableciendo las bases para el an√°lisis y manipulaci√≥n de datos en Python. Se enfoca en:\n",
    "\n",
    "- Importaci√≥n de la librer√≠a pandas\n",
    "    - Dominar la sintaxis para importar pandas y comprender la importancia de usar el alias est√°ndar pd para facilitar el trabajo posterior\n",
    "- Comprensi√≥n de clases y objetos\n",
    "    - Entender que las clases son plantillas para crear objetos, siendo DataFrame() la clase m√°s utilizada en pandas\n",
    "- Creaci√≥n de DataFrames b√°sicos\n",
    "    - Aplicar la clase DataFrame() con sus argumentos data y columns para convertir listas anidadas en estructuras de datos organizadas\n",
    "- Preparaci√≥n de datos estructurados\n",
    "    - Organizar informaci√≥n en listas anidadas que representen filas de datos con caracter√≠sticas espec√≠ficas\n",
    "- Documentaci√≥n de columnas\n",
    "    - Crear listas de nombres descriptivos para las columnas que faciliten la comprensi√≥n de los datos\n",
    "- Visualizaci√≥n de resultados\n",
    "    - Mostrar DataFrames creados para verificar la correcta estructuraci√≥n de los datos\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "\n",
    "### Importaci√≥n de librer√≠a:\n",
    "- import pandas - Importa la librer√≠a pandas completa\n",
    "- import pandas as pd - Importa pandas con alias pd (pr√°ctica est√°ndar)\n",
    "\n",
    "### Creaci√≥n de DataFrame:\n",
    "- pd.DataFrame() - Clase para crear objetos DataFrame\n",
    "- data= - Par√°metro que acepta listas anidadas con los datos\n",
    "- columns= - Par√°metro que acepta lista con nombres de columnas\n",
    "\n",
    "### Estructuras de datos:\n",
    "- [ ] - Listas simples para nombres de columnas\n",
    "- [[ ]] - Listas anidadas para representar filas de datos\n",
    "\n",
    "### Funci√≥n de salida:\n",
    "- print() - Muestra el contenido del DataFrame creado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56f1ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Importaci√≥n est√°ndar:\n",
    "import pandas as pd\n",
    "\n",
    "# Preparaci√≥n de datos:\n",
    "atlas = [\n",
    "    ['France', 'Paris'],\n",
    "    ['Russia', 'Moscow'],\n",
    "    ['China', 'Beijing'],\n",
    "    ['Mexico', 'Mexico City'],\n",
    "    ['Egypt', 'Cairo']\n",
    "]\n",
    "geography = ['country', 'capital']\n",
    "\n",
    "# Creaci√≥n de DataFrame:\n",
    "world_map = pd.DataFrame(data=atlas, columns=geography)\n",
    "print(world_map)\n",
    "# Ejemplo con datos de m√∫sica:\n",
    "music = [\n",
    "    ['Bob Dylan', 'Like A Rolling Stone'],\n",
    "    ['John Lennon', 'Imagine'],\n",
    "    ['The Beatles', 'Hey Jude'],\n",
    "    ['Nirvana', 'Smells Like Teen Spirit']\n",
    "]\n",
    "entries = ['artist', 'track']\n",
    "playlist = pd.DataFrame(data=music, columns=entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d15b704",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Librer√≠a pandas\n",
    "- Colecci√≥n especializada de c√≥digo para procesamiento y an√°lisis de datos, superior a hojas de c√°lculo tradicionales\n",
    "- Alias de importaci√≥n\n",
    "- Pr√°ctica est√°ndar de usar pd como abreviatura para referenciar pandas en el c√≥digo\n",
    "- Clase DataFrame()\n",
    "- Plantilla principal para crear objetos DataFrame que requiere argumentos data y columns\n",
    "- Listas anidadas\n",
    "- Estructura de datos donde cada sublista representa una fila con m√∫ltiples valores relacionados\n",
    "- Argumentos data y columns\n",
    "- Par√°metros esenciales donde data acepta los datos y columns acepta los nombres descriptivos\n",
    "- Conversi√≥n de datos\n",
    "- Proceso de transformar datos sin procesar en estructuras organizadas y etiquetadas\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øPor qu√© crees que es importante estructurar los datos en listas anidadas antes de crear un DataFrame? ¬øQu√© ventajas ofrece pandas DataFrame comparado con trabajar solo con listas de Python para el an√°lisis de datos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc252a7",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Pandas para archivos de Excel y CSV\n",
    "\n",
    "Este cap√≠tulo introduce las t√©cnicas fundamentales para trabajar con archivos de datos externos en pandas, estableciendo las bases para el an√°lisis de datos del mundo real. Se enfoca en:\n",
    "\n",
    "- Transici√≥n de datos creados manualmente a archivos externos\n",
    "    - Comprender que en la pr√°ctica profesional se trabaja con archivos de datos existentes en lugar de crear DataFrames desde listas anidadas\n",
    "- Carga de archivos CSV\n",
    "    - Dominar la funci√≥n pd.read_csv() para importar datos desde archivos de valores separados por comas directamente a DataFrames\n",
    "- Exploraci√≥n inicial de datos\n",
    "    - Aplicar m√©todos como head() y tail() para obtener una vista r√°pida de las primeras y √∫ltimas filas del conjunto de datos\n",
    "- Inspecci√≥n de estructura de datos\n",
    "    - Utilizar el m√©todo info() para comprender la estructura, tipos de datos y caracter√≠sticas generales del DataFrame cargado\n",
    "- Preparaci√≥n para an√°lisis\n",
    "    - Establecer las bases para el an√°lisis de datos mediante la correcta importaci√≥n y exploraci√≥n inicial de conjuntos de datos externos\n",
    "- Trabajo con rutas de archivos\n",
    "    - Comprender c√≥mo especificar correctamente las rutas de archivos para acceder a datos almacenados en el sistema\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "\n",
    "### Importaci√≥n de librer√≠a:\n",
    "- import pandas as pd - Importa pandas con alias est√°ndar para trabajar con datos\n",
    "\n",
    "### Carga de archivos:\n",
    "- pd.read_csv() - Funci√≥n para leer archivos CSV y convertirlos en DataFrames\n",
    "- file_path - Variable para almacenar la ruta del archivo de datos\n",
    "\n",
    "### Exploraci√≥n de datos:\n",
    "- .head() - M√©todo para mostrar las primeras 5 filas del DataFrame\n",
    "- .tail() - M√©todo para mostrar las √∫ltimas 5 filas del DataFrame\n",
    "- .info() - M√©todo para inspeccionar la estructura completa del DataFrame\n",
    "\n",
    "### Funci√≥n de salida:\n",
    "- print() - Muestra el contenido de los m√©todos de exploraci√≥n\n",
    "\n",
    "### Manejo de rutas:\n",
    "- '/datasets/' - Ruta est√°ndar para acceder a archivos de datos en el entorno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f38ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Importaci√≥n de pandas:\n",
    "import pandas as pd\n",
    "\n",
    "# Definir ruta del archivo:\n",
    "file_path = '/datasets/DigiDB_digimonlist.csv'\n",
    "\n",
    "# Cargar datos desde CSV:\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Inspeccionar estructura del dataset:\n",
    "df.info()\n",
    "\n",
    "# Mostrar primeras 5 filas:\n",
    "print(df.head())\n",
    "\n",
    "# Mostrar √∫ltimas 5 filas:\n",
    "print(df.tail())\n",
    "# Ejemplo con datos de diabetes:\n",
    "diabetes_data = pd.read_csv('/datasets/diabetes.csv')\n",
    "diabetes_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9679a7bf",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Archivos CSV\n",
    "- Formato de archivo de valores separados por comas, est√°ndar para almacenar datos tabulares de manera eficiente\n",
    "- Funci√≥n read_csv()\n",
    "- Herramienta principal de pandas para importar datos desde archivos CSV directamente a DataFrames\n",
    "- Exploraci√≥n inicial\n",
    "- Proceso de obtener una vista r√°pida de los datos mediante m√©todos como head() y tail()\n",
    "- M√©todo info()\n",
    "- Funci√≥n que proporciona informaci√≥n detallada sobre la estructura, tipos de datos y memoria utilizada por el DataFrame\n",
    "- Rutas de archivos\n",
    "- Direcciones espec√≠ficas que indican la ubicaci√≥n de los archivos de datos en el sistema de archivos\n",
    "- Transici√≥n a datos reales\n",
    "- Cambio de trabajar con datos creados manualmente a utilizar conjuntos de datos externos del mundo real\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øPor qu√© crees que es importante explorar los datos con head(), tail() e info() antes de comenzar cualquier an√°lisis? ¬øQu√© problemas podr√≠as enfrentar si trabajas con un conjunto de datos sin conocer primero su estructura y caracter√≠sticas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676ec71a",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Indexaci√≥n de un DataFrame\n",
    "Este cap√≠tulo se enfoca en las t√©cnicas fundamentales para acceder y extraer datos espec√≠ficos de DataFrames en pandas. Se centra en:\n",
    "\n",
    "- Comprensi√≥n de la indexaci√≥n\n",
    "    - Entender que los √≠ndices en pandas comienzan en 0 y c√≥mo navegar por las posiciones de filas y columnas\n",
    "- Notaci√≥n abreviada vs completa\n",
    "    - Dominar las diferencias entre df['columna'] para selecci√≥n simple y df.loc[fila, columna] para selecci√≥n espec√≠fica\n",
    "- Selecci√≥n de m√∫ltiples columnas\n",
    "    - Aplicar la t√©cnica de doble corchetes para extraer varias columnas simult√°neamente\n",
    "- Segmentaci√≥n de rangos\n",
    "    - Utilizar rangos de √≠ndices para extraer porciones espec√≠ficas del DataFrame\n",
    "- Extracci√≥n precisa de datos\n",
    "    - Combinar t√©cnicas de indexaci√≥n para obtener exactamente la informaci√≥n necesaria\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "### Selecci√≥n de columnas:\n",
    "- df['columna']\n",
    "### Selecciona una columna espec√≠fica (notaci√≥n abreviada)\n",
    "- df[['col1', 'col2']]\n",
    "- Selecciona m√∫ltiples columnas usando doble corchetes\n",
    "### Indexaci√≥n por posici√≥n:\n",
    "- df.loc[fila, columna]\n",
    "### Selecciona celda espec√≠fica usando notaci√≥n completa\n",
    "- df.loc[inicio:fin]\n",
    "### Selecciona rango de filas\n",
    "- df.loc[inicio:fin, 'columna']\n",
    "- Selecciona rango de filas para columna espec√≠fica\n",
    "### Segmentaci√≥n de rangos:\n",
    "- df.loc[9:19]\n",
    "### Extrae filas de la d√©cima a la vig√©sima (√≠ndices 9-19)\n",
    "- df.loc[:, ['col1', 'col2']]\n",
    "- Selecciona todas las filas para columnas espec√≠ficas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd49e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Ejercicio 1 - Selecci√≥n de columna √∫nica:\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/music_log_chpt_11.csv')\n",
    "\n",
    "index_res = df['user_id']  # Notaci√≥n abreviada\n",
    "\n",
    "print(index_res)\n",
    "\n",
    "# Ejercicio 2 - Segmentaci√≥n de fila espec√≠fica con rango de columnas:\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/music_log_chpt_11.csv')\n",
    "\n",
    "index_res = df.loc[5, 'total play':'genre']  # Sexta fila (√≠ndice 5)\n",
    "\n",
    "print(index_res)\n",
    "\n",
    "# Ejercicio 3 - Selecci√≥n de m√∫ltiples columnas:\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/music_log_chpt_11.csv')\n",
    "\n",
    "index_res = df[['user_id', 'track']]  # Doble corchetes\n",
    "\n",
    "print(index_res)\n",
    "\n",
    "# Ejercicio 4 - Segmentaci√≥n de columna espec√≠fica con rango de filas:\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/music_log_chpt_11.csv')\n",
    "\n",
    "index_res = df.loc[2:10, 'genre']  # Tercera a und√©cima fila (√≠ndices 2-10) de la columna 'genre'\n",
    "\n",
    "print(index_res)\n",
    "\n",
    "# Ejercicio 5 - Extracci√≥n de rango espec√≠fico (d√©cima a vig√©sima fila):\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/music_log_chpt_11.csv')\n",
    "\n",
    "index_res = df.loc[9:19]  # D√©cima a vig√©sima fila (√≠ndices 9-19)\n",
    "\n",
    "print(index_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39853eff",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Indexaci√≥n basada en cero\n",
    "- Los DataFrames usan indexaci√≥n que comienza en 0, donde el d√©cimo elemento tiene √≠ndice 9\n",
    "- Notaci√≥n abreviada\n",
    "- M√©todo r√°pido para acceder a columnas completas usando corchetes simples\n",
    "- Notaci√≥n completa\n",
    "- M√©todo preciso usando .loc[] para especificar exactamente filas y columnas\n",
    "- Segmentaci√≥n inclusiva\n",
    "- Los rangos en pandas incluyen tanto el inicio como el final del rango especificado\n",
    "- Selecci√≥n m√∫ltiple\n",
    "- T√©cnica de usar listas dentro de corchetes para seleccionar varias columnas a la vez\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øC√≥mo te ayudar√° dominar estas t√©cnicas de indexaci√≥n en tus an√°lisis futuros? Piensa en situaciones donde necesitar√≠as extraer datos espec√≠ficos de grandes conjuntos de informaci√≥n y qu√© ventajas ofrece poder hacerlo de manera precisa y eficiente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aa75da",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Indexaci√≥n de un DataFrame\n",
    "Este cap√≠tulo introduce las t√©cnicas fundamentales para acceder y extraer datos espec√≠ficos de DataFrames en pandas, herramientas esenciales para la manipulaci√≥n precisa de datos. Se enfoca en:\n",
    "\n",
    "- Comprensi√≥n de la indexaci√≥n\n",
    "    - Entender que los √≠ndices en pandas comienzan en 0 y c√≥mo el d√©cimo elemento corresponde al √≠ndice 9\n",
    "- Notaci√≥n abreviada vs completa\n",
    "    - Dominar las diferencias entre df['columna'] para selecci√≥n r√°pida y df.loc[fila, columna] para selecci√≥n espec√≠fica\n",
    "- Selecci√≥n de m√∫ltiples columnas\n",
    "    - Aplicar la t√©cnica de doble corchetes para extraer varias columnas simult√°neamente del DataFrame\n",
    "- Segmentaci√≥n de rangos\n",
    "    - Utilizar rangos de √≠ndices para extraer porciones espec√≠ficas de filas y columnas\n",
    "- Extracci√≥n precisa de datos\n",
    "    - Combinar t√©cnicas de indexaci√≥n para obtener exactamente la informaci√≥n necesaria para an√°lisis\n",
    "- Navegaci√≥n eficiente\n",
    "    - Interpretar la importancia de acceder a datos espec√≠ficos sin cargar informaci√≥n innecesaria\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "### Importaci√≥n de librer√≠a:\n",
    "- import pandas as pd\n",
    "- Importa pandas con alias pd (pr√°ctica est√°ndar)\n",
    "### Carga de datos:\n",
    "- pd.read_csv()\n",
    "- Carga archivos CSV en formato DataFrame\n",
    "- '/datasets/music_log_chpt_11.csv'\n",
    "- Ruta del archivo de datos musicales\n",
    "### Selecci√≥n de columnas:\n",
    "- df['columna']\n",
    "- Selecciona una columna espec√≠fica (notaci√≥n abreviada)\n",
    "- df[['col1', 'col2']]\n",
    "- Selecciona m√∫ltiples columnas usando doble corchetes\n",
    "### Indexaci√≥n por posici√≥n:\n",
    "- df.loc[fila, columna]\n",
    "- Selecciona celda espec√≠fica usando notaci√≥n completa\n",
    "- df.loc[inicio:fin]\n",
    "- Selecciona rango de filas\n",
    "- df.loc[inicio:fin, 'columna']\n",
    "- Selecciona rango de filas para columna espec√≠fica\n",
    "###  Segmentaci√≥n de rangos:\n",
    "- df.loc[9:19]\n",
    "- Extrae filas de la d√©cima a la vig√©sima (√≠ndices 9-19)\n",
    "- df.loc[2:10, 'genre']\n",
    "- Extrae filas espec√≠ficas de una columna determinada\n",
    "### Funci√≥n de salida:\n",
    "- print()\n",
    "- Muestra el resultado de las operaciones de indexaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ecf931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Ejercicio 1 - Selecci√≥n de columna √∫nica:\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/music_log_chpt_11.csv')\n",
    "\n",
    "index_res = df['user_id']  # Notaci√≥n abreviada\n",
    "\n",
    "print(index_res)\n",
    "\n",
    "# Ejercicio 2 - Segmentaci√≥n de fila espec√≠fica con rango de columnas:\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/music_log_chpt_11.csv')\n",
    "\n",
    "index_res = df.loc[5, 'total play':'genre']  # Sexta fila (√≠ndice 5)\n",
    "\n",
    "print(index_res)\n",
    "\n",
    "# Ejercicio 3 - Selecci√≥n de m√∫ltiples columnas:\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/music_log_chpt_11.csv')\n",
    "\n",
    "index_res = df[['user_id', 'track']]  # Doble corchetes\n",
    "\n",
    "print(index_res)\n",
    "\n",
    "# Ejercicio 4 - Completado\n",
    "# Enunciado: Utiliza la notaci√≥n abreviada para obtener las filas de la 10 a la 20 (ambas incluidas) del conjunto de datos. Asigna el resultado a la variable index_res.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/music_log_chpt_11.csv')\n",
    "\n",
    "# Usando notaci√≥n abreviada para obtener filas 10-20 (√≠ndices 9-20)\n",
    "index_res = df[9:21]  # Notaci√≥n abreviada excluye el final, por eso usamos 21\n",
    "\n",
    "print(index_res)\n",
    "# Explicaci√≥n: En la notaci√≥n abreviada, los slices excluyen el elemento final del rango, por lo que para incluir la fila 20 (√≠ndice 20), necesitamos usar df[9:21]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21590ae",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Indexaci√≥n por coordenadas: Acceso a celdas espec√≠ficas usando df.loc[fila, columna]\n",
    "- Notaci√≥n completa vs. abreviada:\n",
    "- Completa: .loc[] para especificar filas y columnas expl√≠citamente\n",
    "- Abreviada: Uso directo de corchetes df[] para acceso m√°s conciso\n",
    "- Diferencias importantes en notaci√≥n abreviada:\n",
    "- Los slices excluyen el final del rango\n",
    "- No permite acceso a una sola celda\n",
    "- Limitada para ciertos tipos de selecci√≥n\n",
    "- Tipos de selecci√≥n disponibles:\n",
    "- Una columna: df['columna']\n",
    "- M√∫ltiples columnas: df[['col1', 'col2']]\n",
    "- Rangos de filas: df[inicio:fin]\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øCu√°ndo es m√°s conveniente usar la notaci√≥n completa (.loc[]) versus la notaci√≥n abreviada para indexar un DataFrame, y qu√© ventajas ofrece cada una en diferentes escenarios de an√°lisis de datos?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd26ec6e",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Filtrado con indexaci√≥n l√≥gica\n",
    "Este cap√≠tulo se enfoca en t√©cnicas avanzadas de filtrado de datos usando condiciones l√≥gicas en pandas. Los temas principales incluyen:\n",
    "\n",
    "- Comprensi√≥n de la indexaci√≥n l√≥gica\n",
    "    - Entender c√≥mo usar condiciones booleanas para filtrar filas espec√≠ficas que cumplan criterios determinados\n",
    "- Operadores de comparaci√≥n\n",
    "    - Dominar el uso de operadores como ==, !=, >, <, >=, <= para crear condiciones de filtrado\n",
    "- Filtrado con condiciones simples\n",
    "    - Aplicar filtros b√°sicos usando una sola condici√≥n para obtener subconjuntos de datos\n",
    "- Filtrado con condiciones m√∫ltiples\n",
    "    - Combinar m√∫ltiples condiciones usando operadores l√≥gicos & (and) y | (or)\n",
    "- M√©todo query()\n",
    "    - Utilizar el m√©todo query() como alternativa m√°s legible para filtrar datos con sintaxis similar a SQL\n",
    "- Filtrado por valores espec√≠ficos\n",
    "    - Implementar filtros para buscar valores exactos, rangos o patrones espec√≠ficos en los datos\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "### Importaci√≥n y carga de datos:\n",
    "- import pandas as pd\n",
    "- df = pd.read_csv('archivo.csv')\n",
    "### Operadores de comparaci√≥n:\n",
    "- == - Igual a\n",
    "- != - Diferente de  \n",
    "- > - Mayor que\n",
    "- < - Menor que\n",
    "- >= - Mayor o igual que\n",
    "- <= - Menor o igual que\n",
    "\n",
    "### Filtrado con condiciones simples:\n",
    "- df[df['columna'] == 'valor']\n",
    "- df[df['columna'] > 100]\n",
    "- df[df['columna'] != 'valor']\n",
    "### Operadores l√≥gicos para condiciones m√∫ltiples:\n",
    "- & - Operador AND (y)\n",
    "- | - Operador OR (o)\n",
    "- ~ - Operador NOT (no)\n",
    "\n",
    "### Filtrado con condiciones m√∫ltiples:\n",
    "- df[(df['col1'] > 50) & (df['col2'] == 'valor')]\n",
    "- df[(df['col1'] < 100) | (df['col2'] != 'valor')]\n",
    "- M√©todo query():\n",
    "- df.query('columna > 50')\n",
    "- df.query('col1 > 50 and col2 == \"valor\"')\n",
    "- df.query('col1 < 100 or col2 != \"valor\"')\n",
    "### M√©todos auxiliares:\n",
    "- .isin() - Verificar si valores est√°n en una lista\n",
    "- .between() - Filtrar valores en un rango\n",
    "- .isna() - Detectar valores nulos\n",
    "- .notna() - Detectar valores no nulos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec5c8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "# Filtrado simple\n",
    "usuarios_activos = df[df['status'] == 'active']\n",
    "\n",
    "# Filtrado m√∫ltiple\n",
    "usuarios_premium = df[(df['plan'] == 'premium') & (df['age'] >= 18)]\n",
    "\n",
    "# Usando query()\n",
    "resultado = df.query('age > 25 and city == \"Madrid\"')\n",
    "\n",
    "# Usando isin()\n",
    "ciudades_principales = df[df['city'].isin(['Madrid', 'Barcelona', 'Valencia'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b3fdd7",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Indexaci√≥n l√≥gica\n",
    "- T√©cnica que permite filtrar DataFrames usando condiciones booleanas que eval√∫an cada fila\n",
    "- M√°scaras booleanas\n",
    "- Arrays de valores True/False que determinan qu√© filas incluir en el resultado filtrado\n",
    "- Operadores de comparaci√≥n\n",
    "- S√≠mbolos que permiten comparar valores de columnas con valores espec√≠ficos o otras columnas\n",
    "- Operadores l√≥gicos\n",
    "- Herramientas para combinar m√∫ltiples condiciones: & (and), | (or), ~ (not)\n",
    "- M√©todo query()\n",
    "- Alternativa m√°s legible para filtrar datos usando sintaxis similar a SQL, especialmente √∫til para condiciones complejas\n",
    "- Filtrado condicional\n",
    "- Proceso de seleccionar subconjuntos de datos bas√°ndose en criterios espec√≠ficos que deben cumplir las filas\n",
    "- Encadenamiento de condiciones\n",
    "- T√©cnica para combinar m√∫ltiples filtros usando par√©ntesis y operadores l√≥gicos para crear criterios complejos\n",
    "- M√©todos auxiliares de filtrado\n",
    "- Funciones especializadas como .isin(), .between(), .isna() y .notna() que facilitan tipos espec√≠ficos de filtrado\n",
    "- Sintaxis de par√©ntesis\n",
    "- Uso obligatorio de par√©ntesis al combinar condiciones m√∫ltiples para evitar errores de precedencia de operadores\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øEn qu√© situaciones del an√°lisis de datos reales ser√≠a m√°s eficiente usar el m√©todo query() en lugar de la indexaci√≥n l√≥gica tradicional con corchetes, y c√≥mo puede el filtrado con m√∫ltiples condiciones ayudarte a obtener insights m√°s espec√≠ficos de tus datos?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ac23f6",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Vamos a contar y sumar\n",
    "Este cap√≠tulo introduce las t√©cnicas fundamentales de agregaci√≥n y c√°lculo estad√≠stico en pandas, herramientas esenciales para el an√°lisis cuantitativo de datos. Se enfoca en:\n",
    "\n",
    "- Comprensi√≥n de m√©todos de agregaci√≥n\n",
    "    - Entender las funciones estad√≠sticas b√°sicas que permiten resumir y analizar grandes vol√∫menes de datos de manera eficiente\n",
    "- Conteo de elementos\n",
    "    - Dominar el uso de .count() para determinar la cantidad de valores no nulos en columnas espec√≠ficas\n",
    "- Suma de valores num√©ricos\n",
    "    - Aplicar el m√©todo .sum() para calcular totales de columnas num√©ricas y obtener insights cuantitativos\n",
    "- C√°lculo de promedios\n",
    "    - Utilizar .mean() para obtener valores promedio que representen tendencias centrales en los datos\n",
    "- Valores extremos\n",
    "    - Implementar .min() y .max() para identificar los valores m√≠nimos y m√°ximos en conjuntos de datos\n",
    "- Agregaci√≥n por grupos\n",
    "    - Combinar m√©todos de agregaci√≥n con filtrado para obtener estad√≠sticas espec√≠ficas de subconjuntos de datos\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "### Importaci√≥n y carga de datos:\n",
    "- import pandas as pd - Importa pandas con alias pd (pr√°ctica est√°ndar)\n",
    "- pd.read_csv() - Carga archivos CSV en formato DataFrame\n",
    "\n",
    "### M√©todos de conteo:\n",
    "- .count() - Cuenta valores no nulos en una columna o DataFrame\n",
    "- .value_counts() - Cuenta frecuencia de valores √∫nicos\n",
    "- .nunique() - Cuenta valores √∫nicos en una columna\n",
    "\n",
    "### M√©todos de suma:\n",
    "- .sum() - Suma todos los valores num√©ricos de una columna\n",
    "- .cumsum() - Suma acumulativa de valores\n",
    "\n",
    "### M√©todos estad√≠sticos b√°sicos:\n",
    "- .mean() - Calcula el promedio aritm√©tico\n",
    "- .median() - Calcula la mediana\n",
    "- .mode() - Encuentra el valor m√°s frecuente\n",
    "\n",
    "### M√©todos de valores extremos:\n",
    "- .min() - Encuentra el valor m√≠nimo\n",
    "- .max() - Encuentra el valor m√°ximo\n",
    "- .idxmin() - Encuentra el √≠ndice del valor m√≠nimo\n",
    "- .idxmax() - Encuentra el √≠ndice del valor m√°ximo\n",
    "\n",
    "### M√©todos de agregaci√≥n m√∫ltiple:\n",
    "- .describe() - Genera estad√≠sticas descriptivas completas\n",
    "- .agg() - Aplica m√∫ltiples funciones de agregaci√≥n\n",
    "\n",
    "### Funci√≥n de salida:\n",
    "- print() - Muestra los resultados de los c√°lculos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dcc5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Conteo b√°sico:\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/music_log.csv')\n",
    "\n",
    "# Contar valores no nulos\n",
    "total_registros = df['user_id'].count()\n",
    "print(total_registros)\n",
    "\n",
    "# Suma de valores:\n",
    "# Sumar valores num√©ricos\n",
    "total_reproducciones = df['total_play'].sum()\n",
    "print(total_reproducciones)\n",
    "\n",
    "# C√°lculo de promedio:\n",
    "\n",
    "# Calcular promedio\n",
    "promedio_reproducciones = df['total_play'].mean()\n",
    "print(promedio_reproducciones)\n",
    "\n",
    "# Valores extremos:\n",
    "\n",
    "# Encontrar valores m√≠nimo y m√°ximo\n",
    "min_reproducciones = df['total_play'].min()\n",
    "max_reproducciones = df['total_play'].max()\n",
    "print(f\"M√≠nimo: {min_reproducciones}, M√°ximo: {max_reproducciones}\")\n",
    "\n",
    "# Estad√≠sticas descriptivas completas:\n",
    "# Resumen estad√≠stico completo\n",
    "estadisticas = df['total_play'].describe()\n",
    "print(estadisticas)\n",
    "\n",
    "# Conteo de valores √∫nicos:\n",
    "# Contar g√©neros √∫nicos\n",
    "generos_unicos = df['genre'].nunique()\n",
    "print(f\"G√©neros √∫nicos: {generos_unicos}\")\n",
    "\n",
    "# Frecuencia de cada g√©nero\n",
    "frecuencia_generos = df['genre'].value_counts()\n",
    "print(frecuencia_generos)\n",
    "\n",
    "# Filtrado combinado con agregaci√≥n:\n",
    "# Promedio de reproducciones por g√©nero espec√≠fico\n",
    "jazz_promedio = df[df['genre'] == 'jazz']['total_play'].mean()\n",
    "rock_total = df[df['genre'] == 'rock']['total_play'].sum()\n",
    "\n",
    "print(f\"Promedio jazz: {jazz_promedio}\")\n",
    "print(f\"Total rock: {rock_total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639f2e7d",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- M√©todos de agregaci√≥n\n",
    "- Funciones estad√≠sticas que resumen grandes conjuntos de datos en valores √∫nicos representativos\n",
    "- Funci√≥n count()\n",
    "- M√©todo que cuenta elementos no nulos, √∫til para determinar la completitud de los datos\n",
    "- Funci√≥n sum()\n",
    "- Herramienta para calcular totales num√©ricos, esencial para an√°lisis de vol√∫menes y cantidades\n",
    "- Estad√≠sticas descriptivas\n",
    "- Conjunto de medidas (media, mediana, m√≠nimo, m√°ximo) que caracterizan la distribuci√≥n de los datos\n",
    "- Valores extremos\n",
    "- Identificaci√≥n de m√≠nimos y m√°ximos que pueden revelar outliers o rangos de datos importantes\n",
    "- Agregaci√≥n condicional\n",
    "- Combinaci√≥n de filtrado con m√©todos estad√≠sticos para obtener insights espec√≠ficos de subgrupos\n",
    "- An√°lisis exploratorio\n",
    "- Uso de m√©todos de agregaci√≥n para comprender r√°pidamente las caracter√≠sticas principales de un dataset\n",
    "- M√©todos auxiliares\n",
    "- Funciones especializadas como .describe(), .value_counts() y .nunique() que facilitan el an√°lisis inicial\n",
    "- Interpretaci√≥n de resultados\n",
    "- Capacidad de extraer conclusiones significativas de los valores estad√≠sticos calculados\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øC√≥mo pueden los m√©todos de agregaci√≥n como count(), sum() y mean() ayudarte a identificar patrones y tendencias en datos musicales que no ser√≠an evidentes al examinar filas individuales, y qu√© tipo de decisiones de negocio podr√≠as tomar bas√°ndote en estos insights agregados?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36052a8",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Solucionar problemas con archivos CSV\n",
    "Este cap√≠tulo aborda los problemas m√°s comunes al trabajar con archivos CSV y las t√©cnicas para resolverlos usando pandas. Se enfoca en:\n",
    "\n",
    "- Identificaci√≥n de problemas comunes en CSV\n",
    "    - Reconocer errores t√≠picos como separadores incorrectos, codificaci√≥n de caracteres, y encabezados mal formateados\n",
    "- Manejo de separadores personalizados\n",
    "    - Dominar el uso del par√°metro sep para trabajar con archivos que usan delimitadores diferentes a la coma\n",
    "- Gesti√≥n de encabezados\n",
    "    - Controlar c√≥mo pandas interpreta las primeras filas usando los par√°metros header y names\n",
    "- Codificaci√≥n de caracteres\n",
    "    - Resolver problemas de caracteres especiales y acentos usando el par√°metro encoding\n",
    "- Tratamiento de valores faltantes\n",
    "    - Manejar celdas vac√≠as y valores nulos usando par√°metros como na_values y keep_default_na\n",
    "- Especificaci√≥n de tipos de datos\n",
    "    - Controlar c√≥mo pandas interpreta las columnas usando el par√°metro dtype\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "### Importaci√≥n y carga b√°sica:\n",
    "- import pandas as pd - Importa pandas con alias pd\n",
    "- pd.read_csv() - Funci√≥n principal para leer archivos CSV\n",
    "\n",
    "### Par√°metros para separadores:\n",
    "- sep=',' - Especifica coma como separador (por defecto)\n",
    "- sep=';' - Especifica punto y coma como separador\n",
    "- sep='\\t' - Especifica tabulaci√≥n como separador\n",
    "- delimiter= - Alternativa a sep para especificar delimitador\n",
    "\n",
    "### Par√°metros para encabezados:\n",
    "- header=0 - Primera fila como encabezado (por defecto)\n",
    "- header=None - Sin encabezados en el archivo\n",
    "- names=['col1', 'col2'] - Asigna nombres personalizados a columnas\n",
    "- skiprows=n - Omite las primeras n filas\n",
    "\n",
    "### Par√°metros para codificaci√≥n:\n",
    "- encoding='utf-8' - Codificaci√≥n UTF-8 (recomendada)\n",
    "- encoding='latin-1' - Codificaci√≥n Latin-1 para caracteres especiales\n",
    "- encoding='cp1252' - Codificaci√≥n Windows\n",
    "\n",
    "### Par√°metros para valores faltantes:\n",
    "- na_values=['', 'NULL', 'N/A'] - Define valores que se interpretan como NaN\n",
    "- keep_default_na=True - Mantiene valores NaN por defecto\n",
    "- na_filter=False - Desactiva detecci√≥n autom√°tica de valores nulos\n",
    "\n",
    "### Par√°metros para tipos de datos:\n",
    "- dtype={'columna': 'str'} - Especifica tipo string para una columna\n",
    "- dtype={'columna': 'int64'} - Especifica tipo entero\n",
    "- dtype={'columna': 'float64'} - Especifica tipo decimal\n",
    "\n",
    "### Funciones de diagn√≥stico:\n",
    "- .info() - Muestra informaci√≥n sobre el DataFrame\n",
    "- .head() - Muestra las primeras filas\n",
    "- .dtypes - Muestra tipos de datos de las columnas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5b7544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Problema con separadores:\n",
    "import pandas as pd\n",
    "\n",
    "# Archivo con punto y coma como separador\n",
    "df = pd.read_csv('/datasets/datos.csv', sep=';')\n",
    "print(df.head())\n",
    "\n",
    "# Problema con codificaci√≥n:\n",
    "# Archivo con caracteres especiales\n",
    "df = pd.read_csv('/datasets/datos.csv', encoding='latin-1')\n",
    "print(df.head())\n",
    "\n",
    "# Problema con encabezados:\n",
    "# Archivo sin encabezados\n",
    "df = pd.read_csv('/datasets/datos.csv', \n",
    "                 header=None, \n",
    "                 names=['nombre', 'edad', 'ciudad'])\n",
    "print(df.info())\n",
    "\n",
    "# Problema con valores faltantes:\n",
    "# Definir valores personalizados como NaN\n",
    "df = pd.read_csv('/datasets/datos.csv', \n",
    "                 na_values=['', 'NULL', 'N/A', 'missing'])\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Problema con tipos de datos:\n",
    "# Forzar tipos de datos espec√≠ficos\n",
    "df = pd.read_csv('/datasets/datos.csv', \n",
    "                 dtype={'id': 'str', 'precio': 'float64'})\n",
    "print(df.dtypes)\n",
    "\n",
    "# Combinaci√≥n de m√∫ltiples par√°metros:\n",
    "# Soluci√≥n completa para archivo problem√°tico\n",
    "df = pd.read_csv('/datasets/datos_problematicos.csv',\n",
    "                 sep=';',\n",
    "                 encoding='utf-8',\n",
    "                 header=0,\n",
    "                 na_values=['', 'NULL', 'N/A'],\n",
    "                 dtype={'codigo': 'str'})\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe44197",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Separadores personalizados\n",
    "- Diferentes caracteres delimitadores (coma, punto y coma, tabulaci√≥n) que pueden usarse para separar columnas en archivos CSV\n",
    "- Codificaci√≥n de caracteres\n",
    "- Sistemas de representaci√≥n de texto (UTF-8, Latin-1, CP1252) que determinan c√≥mo se interpretan caracteres especiales y acentos\n",
    "- Gesti√≥n de encabezados\n",
    "- Control sobre c√≥mo pandas identifica y asigna nombres a las columnas del DataFrame\n",
    "- Valores faltantes personalizados\n",
    "- Definici√≥n de cadenas espec√≠ficas que deben interpretarse como valores nulos o ausentes\n",
    "- Tipos de datos expl√≠citos\n",
    "- Especificaci√≥n manual del tipo de dato para cada columna para evitar interpretaciones incorrectas autom√°ticas\n",
    "- Diagn√≥stico de problemas\n",
    "- T√©cnicas para identificar y analizar errores en la carga de datos usando m√©todos como .info() y .head()\n",
    "- Par√°metros de pd.read_csv()\n",
    "- Conjunto completo de argumentos disponibles para personalizar la lectura de archivos CSV seg√∫n necesidades espec√≠ficas\n",
    "- Troubleshooting sistem√°tico\n",
    "- Metodolog√≠a paso a paso para identificar y resolver problemas comunes en archivos CSV\n",
    "- Validaci√≥n de datos\n",
    "- Verificaci√≥n de que los datos se han cargado correctamente despu√©s de aplicar las correcciones\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øPor qu√© es crucial identificar y resolver problemas de formato en archivos CSV antes de comenzar cualquier an√°lisis de datos, y c√≥mo puede un archivo mal cargado afectar la validez de tus conclusiones y decisiones basadas en datos?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9797189a",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: C√≥mo leer archivos Excel\n",
    "Este cap√≠tulo introduce las t√©cnicas para trabajar con archivos Excel usando pandas, abordando las particularidades de este formato de datos. Se enfoca en:\n",
    "\n",
    "- Comprensi√≥n del formato Excel\n",
    "    - Entender las diferencias entre archivos Excel (.xlsx, .xls) y CSV, incluyendo hojas m√∫ltiples y formato complejo\n",
    "- Funci√≥n pd.read_excel()\n",
    "    - Dominar la funci√≥n principal para cargar archivos Excel en DataFrames de pandas\n",
    "- Manejo de hojas m√∫ltiples\n",
    "    - Controlar qu√© hoja espec√≠fica cargar usando el par√°metro sheet_name y trabajar con libros de m√∫ltiples hojas\n",
    "- Gesti√≥n de rangos de celdas\n",
    "    - Especificar rangos espec√≠ficos de datos usando par√°metros como usecols y skiprows\n",
    "- Tratamiento de encabezados en Excel\n",
    "    - Manejar encabezados complejos y filas de t√≠tulo que son comunes en archivos Excel\n",
    "- Instalaci√≥n de dependencias\n",
    "    - Configurar las librer√≠as necesarias (openpyxl, xlrd) para leer diferentes versiones de Excel\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "### Importaci√≥n y carga b√°sica:\n",
    "- import pandas as pd - Importa pandas con alias pd\n",
    "- pd.read_excel() - Funci√≥n principal para leer archivos Excel\n",
    "\n",
    "### Par√°metros para archivos y hojas:\n",
    "- sheet_name=0 - Lee la primera hoja (por defecto)\n",
    "- sheet_name='Hoja1' - Lee hoja por nombre espec√≠fico\n",
    "- sheet_name=None - Lee todas las hojas en un diccionario\n",
    "- sheet_name=[0, 1] - Lee m√∫ltiples hojas espec√≠ficas\n",
    "\n",
    "### Par√°metros para rangos de datos:\n",
    "- usecols='A:C' - Especifica columnas por rango de letras\n",
    "- usecols=[0, 1, 2] - Especifica columnas por n√∫meros de √≠ndice\n",
    "- usecols=['nombre', 'edad'] - Especifica columnas por nombres\n",
    "- skiprows=n - Omite las primeras n filas\n",
    "\n",
    "### Par√°metros para encabezados:\n",
    "- header=0 - Primera fila como encabezado (por defecto)\n",
    "- header=None - Sin encabezados en el archivo\n",
    "- names=['col1', 'col2'] - Asigna nombres personalizados a columnas\n",
    "\n",
    "### Par√°metros para valores faltantes:\n",
    "- na_values=['', 'NULL', 'N/A'] - Define valores que se interpretan como NaN\n",
    "- keep_default_na=True - Mantiene valores NaN por defecto\n",
    "\n",
    "### Par√°metros para tipos de datos:\n",
    "- dtype={'columna': 'str'} - Especifica tipo de dato para columnas\n",
    "- converters={'col': funci√≥n} - Aplica funci√≥n personalizada a columna\n",
    "\n",
    "### Funciones de diagn√≥stico:\n",
    "- .info() - Muestra informaci√≥n sobre el DataFrame\n",
    "- .head() - Muestra las primeras filas\n",
    "- .sheet_names - Lista nombres de hojas disponibles (para ExcelFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62210a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "# Carga b√°sica de Excel:\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar archivo Excel b√°sico\n",
    "df = pd.read_excel('/datasets/ventas.xlsx')\n",
    "print(df.head())\n",
    "\n",
    "# Especificar hoja por nombre:\n",
    "# Cargar hoja espec√≠fica por nombre\n",
    "df = pd.read_excel('/datasets/ventas.xlsx', sheet_name='Enero')\n",
    "print(df.info())\n",
    "\n",
    "# Cargar m√∫ltiples hojas:\n",
    "# Cargar todas las hojas\n",
    "todas_hojas = pd.read_excel('/datasets/ventas.xlsx', sheet_name=None)\n",
    "print(todas_hojas.keys())\n",
    "\n",
    "# Cargar hojas espec√≠ficas\n",
    "hojas_seleccionadas = pd.read_excel('/datasets/ventas.xlsx', \n",
    "                                   sheet_name=['Enero', 'Febrero'])\n",
    "print(hojas_seleccionadas['Enero'].head())\n",
    "\n",
    "# Especificar rangos de columnas:\n",
    "# Cargar solo columnas espec√≠ficas\n",
    "df = pd.read_excel('/datasets/ventas.xlsx', \n",
    "                   usecols='A:D')  # Columnas A hasta D\n",
    "print(df.head())\n",
    "\n",
    "# Cargar columnas por nombre\n",
    "df = pd.read_excel('/datasets/ventas.xlsx', \n",
    "                   usecols=['producto', 'precio', 'cantidad'])\n",
    "print(df.head())\n",
    "\n",
    "# Manejar filas de encabezado complejas:\n",
    "# Omitir filas de t√≠tulo y usar fila espec√≠fica como encabezado\n",
    "df = pd.read_excel('/datasets/reporte.xlsx', \n",
    "                   skiprows=3, \n",
    "                   header=0)\n",
    "print(df.head())\n",
    "\n",
    "# Trabajar con ExcelFile para m√∫ltiples operaciones:\n",
    "# Usar ExcelFile para operaciones m√∫ltiples\n",
    "excel_file = pd.ExcelFile('/datasets/ventas.xlsx')\n",
    "print(excel_file.sheet_names)\n",
    "\n",
    "# Cargar hojas individualmente\n",
    "enero = excel_file.parse('Enero')\n",
    "febrero = excel_file.parse('Febrero', usecols=['producto', 'ventas'])\n",
    "print(enero.head())\n",
    "\n",
    "# Combinaci√≥n de par√°metros avanzados:\n",
    "# Configuraci√≥n completa para archivo Excel complejo\n",
    "df = pd.read_excel('/datasets/datos_complejos.xlsx',\n",
    "                   sheet_name='Datos',\n",
    "                   skiprows=2,\n",
    "                   usecols='B:F',\n",
    "                   header=0,\n",
    "                   na_values=['', 'N/A', 'NULL'],\n",
    "                   dtype={'codigo': 'str'})\n",
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf90c0f",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Formato Excel vs CSV\n",
    "- Diferencias fundamentales entre archivos Excel (formato binario con m√∫ltiples hojas) y CSV (texto plano con una sola tabla)\n",
    "- Funci√≥n pd.read_excel()\n",
    "- Herramienta principal de pandas para cargar archivos Excel con capacidades avanzadas de configuraci√≥n\n",
    "- Hojas m√∫ltiples (worksheets)\n",
    "- Capacidad de los archivos Excel para contener m√∫ltiples tablas de datos en un solo archivo\n",
    "- Par√°metro sheet_name\n",
    "- Control espec√≠fico sobre qu√© hoja o hojas cargar del archivo Excel\n",
    "- Rangos de celdas\n",
    "- Especificaci√≥n de √°reas espec√≠ficas del archivo Excel usando notaci√≥n de columnas (A:C) o √≠ndices num√©ricos\n",
    "- ExcelFile object\n",
    "- Objeto especializado para trabajar eficientemente con archivos Excel que requieren m√∫ltiples operaciones de lectura\n",
    "- Dependencias externas\n",
    "- Librer√≠as adicionales (openpyxl, xlrd) necesarias para leer diferentes versiones de archivos Excel\n",
    "- Encabezados complejos\n",
    "- Manejo de estructuras de encabezado t√≠picas de Excel como t√≠tulos, subt√≠tulos y filas de metadatos\n",
    "- Optimizaci√≥n de memoria\n",
    "- T√©cnicas para cargar solo los datos necesarios usando usecols y skiprows para archivos Excel grandes\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øEn qu√© situaciones ser√≠a m√°s ventajoso usar archivos Excel en lugar de CSV para almacenar y compartir datos, y c√≥mo pueden las caracter√≠sticas √∫nicas de Excel (como m√∫ltiples hojas y formato complejo) tanto beneficiar como complicar el proceso de an√°lisis de datos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42f6778",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Observaci√≥n de los datos\n",
    "Este cap√≠tulo introduce la observaci√≥n de datos, una t√©cnica fundamental para obtener una comprensi√≥n inicial de datasets antes de realizar an√°lisis m√°s profundos. Se enfoca en:\n",
    "\n",
    "- An√°lisis estad√≠stico descriptivo\n",
    "    - Obtener res√∫menes estad√≠sticos completos de columnas num√©ricas usando el m√©todo describe()\n",
    "- Comprensi√≥n de distribuciones de datos\n",
    "    - Identificar medidas de tendencia central, dispersi√≥n y valores extremos en el dataset\n",
    "- Evaluaci√≥n de calidad de datos\n",
    "    - Detectar valores nulos y comprender la estructura general del conjunto de datos\n",
    "- Interpretaci√≥n de estad√≠sticas b√°sicas\n",
    "    - Analizar count, mean, std, min, max y cuartiles para comprender el comportamiento de los datos\n",
    "- Diferenciaci√≥n entre tipos de datos\n",
    "    - Distinguir entre el tratamiento estad√≠stico de columnas num√©ricas y categ√≥ricas\n",
    "- Preparaci√≥n para an√°lisis posteriores\n",
    "    - Establecer una base s√≥lida de conocimiento sobre el dataset antes de aplicar t√©cnicas m√°s avanzadas\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "### Importaci√≥n de librer√≠as:\n",
    "- import pandas as pd - Importa la librer√≠a pandas para manipulaci√≥n de datos\n",
    "\n",
    "### M√©todo principal de observaci√≥n:\n",
    "- .describe() - Genera estad√≠sticas descriptivas para columnas num√©ricas y categ√≥ricas\n",
    "\n",
    "### Configuraci√≥n de lectura de datos:\n",
    "- pd.read_csv() - Lee archivos CSV con configuraciones espec√≠ficas\n",
    "- sep='|' - Especifica el separador de columnas\n",
    "- header=None - Indica que no hay encabezados en el archivo\n",
    "- names=[] - Asigna nombres personalizados a las columnas\n",
    "- decimal=',' - Define el separador decimal\n",
    "\n",
    "### Funci√≥n de salida:\n",
    "- print() - Muestra los resultados estad√≠sticos en pantalla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b39fbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Configuraci√≥n de nombres de columnas:\n",
    "column_names = [\n",
    "    'country',\n",
    "    'name', \n",
    "    'capacity_mw',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'primary_fuel',\n",
    "    'owner'\n",
    "]\n",
    "\n",
    "# Lectura de datos con configuraci√≥n espec√≠fica:\n",
    "data = pd.read_csv(\n",
    "    '/datasets/gpp_modified.csv',\n",
    "    sep='|',\n",
    "    header=None,\n",
    "    names=column_names,\n",
    "    decimal=',',\n",
    ")\n",
    "\n",
    "# Aplicaci√≥n del m√©todo describe():\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85035e1a",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Estad√≠sticas descriptivas - Conjunto de medidas que resumen las caracter√≠sticas principales de un dataset\n",
    "- Count - N√∫mero de valores no nulos en cada columna\n",
    "- Mean - Media aritm√©tica de los valores num√©ricos\n",
    "- Std - Desviaci√≥n est√°ndar que mide la dispersi√≥n de los datos\n",
    "- Min/Max - Valores m√≠nimo y m√°ximo en cada columna\n",
    "- Cuartiles (25%, 50%, 75%) - Valores que dividen los datos en cuatro partes iguales\n",
    "- Unique - N√∫mero de valores √∫nicos en columnas categ√≥ricas\n",
    "- Top - Valor m√°s frecuente en columnas categ√≥ricas\n",
    "- Freq - Frecuencia del valor m√°s com√∫n en columnas categ√≥ricas\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øC√≥mo crees que el dominio de la observaci√≥n de datos te ayudar√° a identificar patrones y problemas potenciales en tus futuros an√°lisis de datos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56d5e78",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Descripciones num√©ricas y describe()\n",
    "Este cap√≠tulo introduce las descripciones num√©ricas utilizando el m√©todo describe(), una t√©cnica fundamental para obtener res√∫menes estad√≠sticos detallados de datasets. Se enfoca en:\n",
    "\n",
    "- An√°lisis estad√≠stico preliminar\n",
    "    - Computar una vista preliminar descriptiva para cada columna num√©rica del dataset de manera autom√°tica\n",
    "- Comprensi√≥n de medidas estad√≠sticas b√°sicas\n",
    "    - Interpretar estad√≠sticas como count, mean, std, min, max y cuartiles para entender la distribuci√≥n de datos\n",
    "- Evaluaci√≥n de tendencia central y dispersi√≥n\n",
    "    - Analizar la media aritm√©tica y desviaci√≥n est√°ndar para comprender el comportamiento t√≠pico de los datos\n",
    "- Identificaci√≥n de valores extremos\n",
    "    - Detectar valores m√≠nimos y m√°ximos que pueden indicar outliers o rangos de datos\n",
    "- An√°lisis de distribuci√≥n por cuartiles\n",
    "    - Utilizar percentiles (25%, 50%, 75%) para entender c√≥mo se distribuyen los valores en el dataset\n",
    "- Exclusi√≥n autom√°tica de valores nulos\n",
    "    - Comprender que todas las estad√≠sticas se calculan √∫nicamente sobre datos no nulos de cada columna\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "### Importaci√≥n de librer√≠as:\n",
    "- import pandas as pd - Importa la librer√≠a pandas para manipulaci√≥n de datos\n",
    "\n",
    "### M√©todo principal de descripci√≥n estad√≠stica:\n",
    "- .describe() - Genera resumen estad√≠stico detallado para columnas num√©ricas del DataFrame\n",
    "\n",
    "### Configuraci√≥n de lectura de datos:\n",
    "- pd.read_csv() - Lee archivos CSV con configuraciones espec√≠ficas\n",
    "- sep='|' - Especifica el separador de columnas como pipe\n",
    "- header=None - Indica ausencia de encabezados en el archivo original\n",
    "- names=[] - Asigna nombres personalizados a las columnas del DataFrame\n",
    "- decimal=',' - Define la coma como separador decimal\n",
    "\n",
    "### Funci√≥n de salida:\n",
    "- print() - Muestra el resumen estad√≠stico en pantalla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67062851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Configuraci√≥n de nombres de columnas:\n",
    "column_names = [\n",
    "    'country',\n",
    "    'name',\n",
    "    'capacity_mw',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'primary_fuel',\n",
    "    'owner'\n",
    "]\n",
    "\n",
    "# Lectura de datos con configuraci√≥n espec√≠fica:\n",
    "data = pd.read_csv(\n",
    "    '/datasets/gpp_modified.csv',\n",
    "    sep='|',\n",
    "    header=None,\n",
    "    names=column_names,\n",
    "    decimal=',',\n",
    ")\n",
    "\n",
    "# Aplicaci√≥n del m√©todo describe():\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fff75e",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Count - N√∫mero de observaciones no nulas en cada columna num√©rica\n",
    "- Mean - Media aritm√©tica que representa el valor promedio de los datos\n",
    "- Std - Desviaci√≥n est√°ndar que mide la dispersi√≥n de los datos respecto a la media\n",
    "- Min - Valor m√≠nimo encontrado en cada columna num√©rica\n",
    "- 25% (Primer cuartil) - Valor por debajo del cual se encuentra el 25% de los datos\n",
    "- 50% (Mediana) - Valor central que divide los datos en dos mitades iguales\n",
    "- 75% (Tercer cuartil) - Valor por debajo del cual se encuentra el 75% de los datos\n",
    "- Max - Valor m√°ximo encontrado en cada columna num√©rica\n",
    "- Exclusi√≥n autom√°tica de nulos - Todas las estad√≠sticas se calculan √∫nicamente sobre valores no nulos\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øC√≥mo crees que el dominio del m√©todo describe() te ayudar√° a identificar patrones, outliers y caracter√≠sticas importantes de tus datos antes de realizar an√°lisis m√°s profundos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea651bff",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Problemas con los datos: entra basura, sale basura\n",
    "Este cap√≠tulo introduce la identificaci√≥n y correcci√≥n de problemas comunes en los datos, una t√©cnica fundamental para garantizar la calidad de los datos antes del an√°lisis. Se enfoca en:\n",
    "\n",
    "- Principio \"Garbage In, Garbage Out\" (GIGO)\n",
    "    - Comprender que datos de mala calidad producen an√°lisis y conclusiones no confiables\n",
    "- Identificaci√≥n de problemas estructurales\n",
    "    - Detectar errores en el nombramiento de columnas que pueden causar dificultades en el an√°lisis\n",
    "- Correcci√≥n de nombres de columnas\n",
    "    - Aplicar buenas pr√°cticas de nomenclatura usando snake_case y nombres descriptivos\n",
    "- Uso del m√©todo info() para diagn√≥stico\n",
    "    - Obtener una vista general del dataset incluyendo nombres de columnas, tipos de datos y valores no nulos\n",
    "- Renombramiento manual de columnas\n",
    "    - Utilizar el m√©todo rename() con diccionarios para cambiar nombres espec√≠ficos de columnas\n",
    "- Automatizaci√≥n del proceso de limpieza\n",
    "    - Implementar bucles y m√©todos de string para corregir m√∫ltiples columnas de manera eficiente\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "### Importaci√≥n de librer√≠as:\n",
    "- import pandas as pd - Importa la librer√≠a pandas para manipulaci√≥n de datos\n",
    "\n",
    "### M√©todos de diagn√≥stico:\n",
    "- .info() - Muestra informaci√≥n general sobre el DataFrame incluyendo nombres de columnas\n",
    "- .columns - Atributo que muestra √∫nicamente los nombres de las columnas\n",
    "\n",
    "### Creaci√≥n de DataFrames:\n",
    "- pd.DataFrame() - Crea un DataFrame a partir de datos y nombres de columnas\n",
    "- data= - Par√°metro para especificar los datos del DataFrame\n",
    "- columns= - Par√°metro para especificar los nombres de las columnas\n",
    "\n",
    "### M√©todo de renombramiento:\n",
    "- .rename() - Cambia los nombres de las columnas usando un diccionario\n",
    "- columns= - Par√°metro que recibe el diccionario con nombres antiguos y nuevos\n",
    "- inplace=True - Par√°metro que aplica cambios directamente sin reasignaci√≥n\n",
    "\n",
    "### M√©todos de string para limpieza:\n",
    "- .strip() - Elimina espacios al principio y al final de los nombres\n",
    "- .lower() - Convierte todos los caracteres a min√∫sculas\n",
    "- .replace() - Reemplaza espacios entre palabras por guiones bajos\n",
    "\n",
    "### Estructuras de control:\n",
    "- for - Itera sobre los nombres de columnas para procesamiento autom√°tico\n",
    "- .append() - Agrega elementos procesados a una nueva lista\n",
    "\n",
    "### Funci√≥n de salida:\n",
    "- print() - Muestra informaci√≥n sobre columnas y resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e986f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos mostrados:\n",
    "\n",
    "# Ejemplo 1: Renombrar columnas con el m√©todo rename()\n",
    "\n",
    "# Renombrar columnas espec√≠ficas\n",
    "df = df.rename(columns={'old_name': 'new_name', 'User ID': 'user_id'})\n",
    "\n",
    "# Renombrar todas las columnas usando un bucle\n",
    "new_col_names = []\n",
    "for col in df.columns:\n",
    "    new_name = col.strip().lower().replace(' ', '_')\n",
    "    new_col_names.append(new_name)\n",
    "df.columns = new_col_names\n",
    "\n",
    "# Ejemplo 2: Limpieza de nombres de columnas paso a paso\n",
    "\n",
    "# Dataset music_log_raw.csv\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/datasets/music_log_raw.csv')\n",
    "\n",
    "new_col_names = []\n",
    "for col in df.columns:\n",
    "    # 1. Eliminar espacios al inicio y final\n",
    "    clean_name = col.strip()\n",
    "    # 2. Convertir a min√∫sculas\n",
    "    clean_name = clean_name.lower()\n",
    "    # 3. Reemplazar espacios internos con guiones bajos\n",
    "    clean_name = clean_name.replace(' ', '_')\n",
    "    new_col_names.append(clean_name)\n",
    "\n",
    "# Asignar los nuevos nombres\n",
    "df.columns = new_col_names\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b30bf8",
   "metadata": {},
   "source": [
    "### Conceptos cubiertos:\n",
    "- Errores estructurales vs errores de contenido en datasets\n",
    "- Problemas comunes en nombres de columnas:\n",
    "- Espacios en blanco al inicio/final\n",
    "- Espacios internos en nombres\n",
    "- Inconsistencia en may√∫sculas/min√∫sculas\n",
    "- Falta de claridad en la denominaci√≥n\n",
    "- M√©todo .rename() para cambiar nombres espec√≠ficos de columnas\n",
    "- Convenci√≥n snake_case para nombrar columnas y variables\n",
    "- M√©todos de string: .strip(), .lower(), .replace()\n",
    "- Atributo .columns para acceder y modificar nombres de columnas\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øPor qu√© es importante estandarizar los nombres de las columnas antes de comenzar el an√°lisis de datos? Piensa en al menos tres problemas espec√≠ficos que podr√≠an surgir si trabajas con nombres de columnas inconsistentes o mal formateados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd44c0b",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Renombrar columnas\n",
    "Este cap√≠tulo introduce el renombramiento de columnas, una t√©cnica fundamental para corregir problemas estructurales en los nombres de columnas de datasets. Se enfoca en:\n",
    "\n",
    "- Identificaci√≥n de errores estructurales en nombres\n",
    "    - Detectar problemas comunes como espacios en nombres de columnas y falta de claridad en la denominaci√≥n\n",
    "- Aplicaci√≥n de convenciones de nomenclatura\n",
    "    - Implementar snake_case como est√°ndar para nombrar columnas y variables de manera consistente\n",
    "- Uso del m√©todo rename() para correcciones\n",
    "    - Aplicar el m√©todo rename() de pandas para cambiar nombres espec√≠ficos de columnas de manera eficiente\n",
    "- Automatizaci√≥n del proceso de limpieza\n",
    "    - Crear bucles personalizados para procesar m√∫ltiples nombres de columnas de manera sistem√°tica\n",
    "- Mejora de la legibilidad del c√≥digo\n",
    "    - Transformar nombres confusos o problem√°ticos en nombres claros y descriptivos que faciliten el trabajo posterior\n",
    "- Preparaci√≥n para an√°lisis posteriores\n",
    "    - Establecer una base s√≥lida con nombres de columnas consistentes antes de proceder con el an√°lisis de datos\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "### Importaci√≥n de librer√≠as:\n",
    "- import pandas as pd - Importa la librer√≠a pandas para manipulaci√≥n de datos\n",
    "\n",
    "### M√©todo principal de renombramiento:\n",
    "- .rename() - Cambia los nombres de las columnas usando un diccionario de mapeo\n",
    "- columns= - Par√°metro que especifica el diccionario con nombres antiguos y nuevos\n",
    "- inplace=True - Par√°metro opcional que aplica cambios directamente al DataFrame\n",
    "\n",
    "### Acceso y modificaci√≥n de nombres de columnas:\n",
    "- .columns - Atributo que permite acceder y modificar los nombres de las columnas\n",
    "- .columns = new_list - Asigna una nueva lista de nombres a las columnas\n",
    "\n",
    "### M√©todos de procesamiento de strings:\n",
    "- .strip() - Elimina espacios en blanco al principio y al final de los nombres\n",
    "- .lower() - Convierte todos los caracteres a min√∫sculas\n",
    "- .replace() - Reemplaza caracteres espec√≠ficos (como espacios por guiones bajos)\n",
    "\n",
    "### Estructuras de control para automatizaci√≥n:\n",
    "- for - Itera sobre los nombres de columnas existentes\n",
    "- .append() - Agrega nombres procesados a una nueva lista\n",
    "\n",
    "### Funci√≥n de salida:\n",
    "- print() - Muestra los nombres de columnas antes y despu√©s de la transformaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f9429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Renombramiento autom√°tico con bucle personalizado:\n",
    "new_col_names = []\n",
    "for old_name in celestial.columns:\n",
    "    # Primero, elimina los espacios al principio y al final\n",
    "    name_stripped = old_name.strip()\n",
    "    # Luego, pon todas las letras en min√∫sculas\n",
    "    name_lowered = name_stripped.lower()\n",
    "    # Por √∫ltimo, reemplaza los espacios entre palabras por guiones bajos\n",
    "    name_no_spaces = name_lowered.replace(' ', '_')\n",
    "    # Agrega el nuevo nombre a la lista de nuevos nombres de columna\n",
    "    new_col_names.append(name_no_spaces)\n",
    "\n",
    "# Reemplaza los nombres anteriores por los nuevos\n",
    "\n",
    "celestial.columns = new_col_names\n",
    "# Renombramiento usando el m√©todo rename():\n",
    "df = df.rename(columns={\n",
    "    'Old Column Name': 'new_column_name',\n",
    "    'Another Old Name': 'another_new_name'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a7235b",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Identificaci√≥n de valores ausentes: Uso de isna() y isnull() para detectar valores faltantes en datasets\n",
    "- Tipos de valores ausentes: Diferencia entre formas esperadas (None, NaN) e inesperadas (0, '?', 'NN', 'n/a')\n",
    "- Estrategias de procesamiento: Eliminaci√≥n vs. sustituci√≥n de valores ausentes seg√∫n el contexto\n",
    "- M√©todo fillna(): Reemplazo de valores ausentes con valores espec√≠ficos (ej: ceros)\n",
    "- M√©todo dropna(): Eliminaci√≥n de filas o columnas con valores ausentes usando par√°metros subset= y axis=\n",
    "- M√©todo drop(): Control espec√≠fico para eliminar columnas particulares\n",
    "- Par√°metro inplace=: Modificaci√≥n directa del DataFrame sin reasignaci√≥n\n",
    "- An√°lisis contextual: Importancia de entender el origen de los valores ausentes antes de procesarlos\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øC√≥mo determinar√≠as si es mejor eliminar o reemplazar valores ausentes en una columna espec√≠fica de tu dataset, y qu√© factores considerar√≠as para tomar esta decisi√≥n?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26df1dec",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Procesar valores ausentes\n",
    "Este cap√≠tulo introduce el procesamiento de valores ausentes, una t√©cnica fundamental para manejar datos faltantes en datasets y garantizar la calidad del an√°lisis. Se enfoca en:\n",
    "\n",
    "- Identificaci√≥n de valores ausentes\n",
    "- Detectar valores faltantes utilizando m√©todos espec√≠ficos para reconocer diferentes tipos de ausencias en los datos\n",
    "- Comprensi√≥n de tipos de valores ausentes\n",
    "- Distinguir entre valores ausentes esperados (NaN, None) e inesperados ('n/a', '?', 0) seg√∫n el contexto\n",
    "- Estrategias de eliminaci√≥n de datos faltantes\n",
    "- Aplicar m√©todos para remover filas o columnas con valores ausentes cuando sea apropiado para el an√°lisis\n",
    "- T√©cnicas de sustituci√≥n de valores\n",
    "- Reemplazar valores ausentes con valores espec√≠ficos como ceros, promedios o valores por defecto\n",
    "- An√°lisis contextual de ausencias\n",
    "- Evaluar el significado y origen de los valores ausentes para tomar decisiones informadas sobre su tratamiento\n",
    "- Preservaci√≥n de la integridad del dataset\n",
    "- Mantener la estructura y calidad de los datos mientras se procesan las ausencias de manera eficiente\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "### Importaci√≥n de librer√≠as:\n",
    "- import pandas as pd - Importa la librer√≠a pandas para manipulaci√≥n de datos\n",
    "\n",
    "### M√©todos de identificaci√≥n de valores ausentes:\n",
    "- .isna() - Identifica valores ausentes devolviendo True/False para cada celda\n",
    "- .isnull() - M√©todo alternativo para identificar valores ausentes (equivalente a isna())\n",
    "- .sum() - Cuenta el n√∫mero total de valores ausentes cuando se combina con isna()\n",
    "\n",
    "### M√©todos de eliminaci√≥n de valores ausentes:\n",
    "- .dropna() - Elimina filas o columnas que contienen valores ausentes\n",
    "- subset= - Par√°metro que especifica columnas espec√≠ficas para evaluar ausencias\n",
    "- axis= - Par√°metro que define si eliminar filas (0) o columnas (1)\n",
    "- .drop() - Elimina columnas espec√≠ficas del DataFrame\n",
    "\n",
    "### M√©todos de sustituci√≥n de valores ausentes:\n",
    "- .fillna() - Reemplaza valores ausentes con un valor espec√≠fico\n",
    "- value= - Par√°metro que especifica el valor de reemplazo\n",
    "- inplace=True - Par√°metro que aplica cambios directamente al DataFrame\n",
    "\n",
    "### Configuraci√≥n de lectura de datos:\n",
    "- pd.read_csv() - Lee archivos CSV con configuraciones espec√≠ficas\n",
    "- na_values= - Especifica valores adicionales que deben tratarse como ausentes\n",
    "\n",
    "### Funci√≥n de salida:\n",
    "- print() - Muestra informaci√≥n sobre valores ausentes y resultados del procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fc0005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Identificaci√≥n de valores ausentes:\n",
    "print(df.isna().sum())\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Eliminaci√≥n de filas con valores ausentes en columnas espec√≠ficas:\n",
    "df_clean = df.dropna(subset=['track', 'artist', 'genre'])\n",
    "\n",
    "# Eliminaci√≥n de columnas con valores ausentes:\n",
    "df_no_missing_cols = df.dropna(axis=1)\n",
    "\n",
    "# Sustituci√≥n de valores ausentes con ceros:\n",
    "df['plays'] = df['plays'].fillna(0)\n",
    "\n",
    "# Sustituci√≥n con fillna usando inplace:\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Lectura de CSV especificando valores ausentes adicionales:\n",
    "df = pd.read_csv('/datasets/music_log_upd.csv', na_values=['n/a', 'unknown'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07de0cd5",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Valores ausentes esperados - NaN, None y otros valores reconocidos autom√°ticamente por pandas\n",
    "- Valores ausentes inesperados - Strings como 'n/a', '?', 'unknown' que requieren configuraci√≥n espec√≠fica\n",
    "- Par√°metro subset - Permite especificar columnas espec√≠ficas para evaluar la eliminaci√≥n de filas\n",
    "- Par√°metro axis - Controla si se eliminan filas (axis=0) o columnas (axis=1)\n",
    "- Par√°metro na_values - Define valores adicionales que deben tratarse como ausentes durante la lectura\n",
    "- Estrategia de eliminaci√≥n - Remover datos cuando los valores ausentes no aportan informaci√≥n √∫til\n",
    "- Estrategia de sustituci√≥n - Reemplazar ausencias con valores que mantengan la integridad del an√°lisis\n",
    "- An√°lisis de impacto - Evaluar c√≥mo afecta la eliminaci√≥n o sustituci√≥n al tama√±o y representatividad del dataset\n",
    "- Modificaci√≥n inplace - Aplicar cambios directamente al DataFrame original sin crear copias\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øC√≥mo determinar√≠as si es mejor eliminar o reemplazar valores ausentes en una columna espec√≠fica de tu dataset, y qu√© factores considerar√≠as para tomar esta decisi√≥n informada sobre el tratamiento m√°s apropiado?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515813ab",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Procesamiento de valores duplicados\n",
    "Este cap√≠tulo introduce el procesamiento de valores duplicados, una t√©cnica fundamental para identificar y manejar registros repetidos en datasets y garantizar la calidad del an√°lisis. Se enfoca en:\n",
    "\n",
    "- Identificaci√≥n de registros duplicados\n",
    "    - Detectar filas completamente id√©nticas o duplicadas en columnas espec√≠ficas utilizando m√©todos especializados\n",
    "- Comprensi√≥n de tipos de duplicados\n",
    "    - Distinguir entre duplicados completos (toda la fila) y duplicados parciales (columnas espec√≠ficas) seg√∫n el contexto del an√°lisis\n",
    "- Estrategias de eliminaci√≥n de duplicados\n",
    "    - Aplicar m√©todos para remover registros duplicados manteniendo solo la primera o √∫ltima ocurrencia seg√∫n sea necesario\n",
    "- An√°lisis de impacto de duplicados\n",
    "    - Evaluar c√≥mo los registros duplicados afectan la integridad y representatividad de los datos\n",
    "- Preservaci√≥n de registros √∫nicos\n",
    "    - Mantener solo los registros √∫nicos relevantes mientras se eliminan las copias innecesarias\n",
    "- Control de criterios de duplicaci√≥n\n",
    "    - Especificar qu√© columnas considerar para determinar si un registro es duplicado\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "### Importaci√≥n de librer√≠as:\n",
    "- import pandas as pd - Importa la librer√≠a pandas para manipulaci√≥n de datos\n",
    "\n",
    "### Carga de datos:\n",
    "- pd.read_csv() - Lee archivos CSV y carga los datos en un DataFrame\n",
    "\n",
    "### M√©todos de identificaci√≥n de duplicados:\n",
    "- .duplicated() - Identifica filas duplicadas devolviendo True/False para cada fila\n",
    "- .duplicated().sum() - Cuenta el n√∫mero total de duplicados cuando se combina con duplicated()\n",
    "- subset= - Par√°metro que especifica columnas espec√≠ficas para evaluar duplicaci√≥n\n",
    "\n",
    "### M√©todos de eliminaci√≥n de duplicados:\n",
    "- .drop_duplicates() - Elimina filas duplicadas del DataFrame\n",
    "- .drop_duplicates(keep='first') - Elimina duplicados manteniendo la primera ocurrencia\n",
    "- .drop_duplicates(keep='last') - Elimina duplicados manteniendo la √∫ltima ocurrencia\n",
    "- .drop_duplicates(keep=False) - Elimina todas las ocurrencias de duplicados\n",
    "- .drop_duplicates(subset=['columna']) - Elimina duplicados bas√°ndose en columnas espec√≠ficas\n",
    "- inplace=True - Par√°metro que aplica cambios directamente al DataFrame\n",
    "\n",
    "### M√©todos de reindexaci√≥n:\n",
    "- .reset_index() - Reinicia los √≠ndices del DataFrame\n",
    "- .reset_index(drop=True) - Reinicia los √≠ndices eliminando el √≠ndice anterior\n",
    "\n",
    "### M√©todos de an√°lisis de valores √∫nicos:\n",
    "- .unique() - Obtiene los valores √∫nicos de una columna espec√≠fica\n",
    "- .nunique() - Cuenta el n√∫mero de valores √∫nicos en una columna\n",
    "\n",
    "### M√©todos de informaci√≥n del DataFrame:\n",
    "- .shape - Muestra las dimensiones del DataFrame (filas, columnas)\n",
    "- .info() - Proporciona informaci√≥n general sobre el DataFrame\n",
    "\n",
    "### Funci√≥n de salida:\n",
    "- print() - Muestra informaci√≥n sobre duplicados y resultados del procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3dd002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Identificaci√≥n de duplicados completos:\n",
    "print(df.duplicated().sum())\n",
    "\n",
    "# Identificaci√≥n de duplicados en columnas espec√≠ficas:\n",
    "print(df.duplicated(subset=['track', 'artist']).sum())\n",
    "\n",
    "# Eliminaci√≥n de duplicados completos:\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "\n",
    "# Eliminaci√≥n de duplicados en columnas espec√≠ficas:\n",
    "df_clean = df.drop_duplicates(subset=['track', 'artist'])\n",
    "\n",
    "# Eliminaci√≥n manteniendo el √∫ltimo duplicado:\n",
    "df_last = df.drop_duplicates(keep='last')\n",
    "\n",
    "# Eliminaci√≥n usando inplace:\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Verificaci√≥n del tama√±o antes y despu√©s:\n",
    "print(f\"Antes: {df.shape}\")\n",
    "df_clean = df.drop_duplicates()\n",
    "print(f\"Despu√©s: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e8b134",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Duplicados completos - Filas que son id√©nticas en todas sus columnas\n",
    "- Duplicados parciales - Filas que son id√©nticas solo en columnas espec√≠ficas definidas por subset\n",
    "- Par√°metro keep - Controla qu√© duplicado mantener: 'first' (primero), 'last' (√∫ltimo), False (eliminar todos)\n",
    "- Par√°metro subset - Define qu√© columnas considerar para determinar duplicaci√≥n\n",
    "- An√°lisis de impacto - Evaluar c√≥mo los duplicados afectan el tama√±o y representatividad del dataset\n",
    "- Verificaci√≥n de duplicados - Usar duplicated() para identificar la presencia y cantidad de registros duplicados\n",
    "- Estrategia de conservaci√≥n - Decidir qu√© instancia del duplicado mantener seg√∫n el contexto del an√°lisis\n",
    "- Limpieza de datos - Proceso de eliminaci√≥n de duplicados como parte de la preparaci√≥n de datos\n",
    "- Modificaci√≥n inplace - Aplicar cambios de eliminaci√≥n directamente al DataFrame original\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øC√≥mo determinar√≠as qu√© columnas espec√≠ficas considerar al identificar duplicados en tu dataset, y cu√°ndo ser√≠a apropiado mantener el primer duplicado versus el √∫ltimo duplicado encontrado?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52676565",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Agrupaci√≥n de datos duplicados\n",
    "Este cap√≠tulo introduce el procesamiento de datos duplicados, una t√©cnica esencial para identificar y manejar registros repetidos en datasets, garantizando la calidad y precisi√≥n del an√°lisis. Se enfoca en:\n",
    "\n",
    "- Identificaci√≥n de datos duplicados\n",
    "    - Detectar registros duplicados utilizando m√©todos espec√≠ficos para reconocer filas id√©nticas o parcialmente repetidas\n",
    "- Comprensi√≥n de tipos de duplicados\n",
    "    - Distinguir entre duplicados completos (filas id√©nticas) y duplicados parciales (basados en columnas espec√≠ficas)\n",
    "- Estrategias de eliminaci√≥n de duplicados\n",
    "    - Aplicar m√©todos para remover registros duplicados manteniendo solo las primeras o √∫ltimas ocurrencias\n",
    "- T√©cnicas de agrupaci√≥n y agregaci√≥n\n",
    "    - Agrupar datos duplicados y aplicar funciones de agregaci√≥n para consolidar informaci√≥n repetida\n",
    "- An√°lisis contextual de duplicados\n",
    "    - Evaluar el origen y significado de los duplicados para tomar decisiones informadas sobre su tratamiento\n",
    "- Preservaci√≥n de la integridad del dataset\n",
    "    - Mantener la estructura y calidad de los datos mientras se procesan los duplicados de manera eficiente\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "### Importaci√≥n de librer√≠as:\n",
    "- import pandas as pd - Importa la librer√≠a pandas para manipulaci√≥n de datos\n",
    "\n",
    "### M√©todos de identificaci√≥n de duplicados:\n",
    "- .duplicated() - Identifica filas duplicadas devolviendo True/False para cada fila\n",
    "- .duplicated(subset=) - Identifica duplicados basados en columnas espec√≠ficas\n",
    "- .duplicated(keep=) - Especifica qu√© duplicado mantener ('first', 'last', False)\n",
    "- .sum() - Cuenta el n√∫mero total de duplicados cuando se combina con duplicated()\n",
    "\n",
    "### M√©todos de eliminaci√≥n de duplicados:\n",
    "- .drop_duplicates() - Elimina filas duplicadas del DataFrame\n",
    "- subset= - Par√°metro que especifica columnas para evaluar duplicados\n",
    "- keep= - Par√°metro que define qu√© duplicado mantener\n",
    "- inplace=True - Par√°metro que aplica cambios directamente al DataFrame\n",
    "\n",
    "### M√©todos de agrupaci√≥n y agregaci√≥n:\n",
    "- .groupby() - Agrupa datos por una o m√°s columnas\n",
    "- .agg() - Aplica funciones de agregaci√≥n a grupos de datos\n",
    "- .size() - Cuenta el n√∫mero de elementos en cada grupo\n",
    "- .count() - Cuenta valores no nulos en cada grupo\n",
    "- .sum() - Suma valores num√©ricos en cada grupo\n",
    "- .mean() - Calcula la media de valores num√©ricos en cada grupo\n",
    "\n",
    "### Funci√≥n de salida:\n",
    "- print() - Muestra informaci√≥n sobre duplicados y resultados del procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38169c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Identificaci√≥n de duplicados:\n",
    "print(df.duplicated().sum())\n",
    "print(df.duplicated(subset=['track', 'artist']).sum())\n",
    "\n",
    "# Eliminaci√≥n de duplicados completos:\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "\n",
    "# Eliminaci√≥n de duplicados basados en columnas espec√≠ficas:\n",
    "df_unique = df.drop_duplicates(subset=['track', 'artist'], keep='first')\n",
    "\n",
    "# Agrupaci√≥n y agregaci√≥n de duplicados:\n",
    "df_grouped = df.groupby(['track', 'artist']).agg({\n",
    "    'plays': 'sum',\n",
    "    'genre': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Conteo de duplicados por grupo:\n",
    "duplicate_counts = df.groupby(['track', 'artist']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdd7fac",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Duplicados completos - Filas completamente id√©nticas en todas las columnas\n",
    "- Duplicados parciales - Filas que coinciden solo en columnas espec√≠ficas definidas por subset\n",
    "- Par√°metro keep - Controla qu√© duplicado conservar: 'first' (primero), 'last' (√∫ltimo), False (eliminar todos)\n",
    "- Par√°metro subset - Define qu√© columnas considerar para determinar duplicaci√≥n\n",
    "- Agrupaci√≥n por duplicados - Usar groupby() para agrupar registros duplicados antes de procesarlos\n",
    "- Funciones de agregaci√≥n - Aplicar sum(), mean(), count(), first() para consolidar datos duplicados\n",
    "- Estrategias de consolidaci√≥n - Decidir c√≥mo combinar informaci√≥n de registros duplicados\n",
    "- An√°lisis de frecuencia - Contar ocurrencias de duplicados para entender patrones en los datos\n",
    "- Preservaci√≥n de informaci√≥n - Mantener datos relevantes al eliminar o consolidar duplicados\n",
    "- Validaci√≥n post-procesamiento - Verificar que la eliminaci√≥n de duplicados mantenga la integridad del an√°lisis\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øEn qu√© situaciones ser√≠a m√°s apropiado agrupar y agregar datos duplicados en lugar de simplemente eliminarlos, y c√≥mo determinar√≠as qu√© funci√≥n de agregaci√≥n usar para cada columna seg√∫n el tipo de informaci√≥n que contiene?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a5ae2e",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Agrupaci√≥n de datos\n",
    "Este cap√≠tulo introduce las t√©cnicas de agrupaci√≥n de datos, una herramienta fundamental para analizar y resumir informaci√≥n por categor√≠as espec√≠ficas, permitiendo obtener insights valiosos de datasets complejos. Se enfoca en:\n",
    "\n",
    "- Conceptos b√°sicos de agrupaci√≥n\n",
    "    - Comprender c√≥mo agrupar datos por una o m√∫ltiples columnas para crear subconjuntos l√≥gicos de informaci√≥n\n",
    "- Aplicaci√≥n de funciones de agregaci√≥n\n",
    "    - Utilizar funciones estad√≠sticas como suma, promedio, conteo y m√°ximo/m√≠nimo para resumir datos agrupados\n",
    "- Agrupaci√≥n por m√∫ltiples criterios\n",
    "    - Crear grupos complejos utilizando combinaciones de columnas para an√°lisis m√°s detallados\n",
    "- Transformaci√≥n y filtrado de grupos\n",
    "    - Aplicar operaciones espec√≠ficas a cada grupo y filtrar resultados seg√∫n criterios definidos\n",
    "- An√°lisis estad√≠stico por grupos\n",
    "    - Generar estad√≠sticas descriptivas y m√©tricas de rendimiento para cada categor√≠a de datos\n",
    "- Visualizaci√≥n de resultados agrupados\n",
    "    - Presentar los resultados de agrupaci√≥n de manera clara y comprensible para la toma de decisiones\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "### Importaci√≥n de librer√≠as:\n",
    "- import pandas as pd - Importa la librer√≠a pandas para manipulaci√≥n de datos\n",
    "\n",
    "### M√©todos b√°sicos de agrupaci√≥n:\n",
    "- .groupby() - Agrupa datos por una o m√°s columnas especificadas\n",
    "- .groups - Muestra los grupos creados y sus √≠ndices correspondientes\n",
    "- .get_group() - Obtiene un grupo espec√≠fico del objeto agrupado\n",
    "\n",
    "### Funciones de agregaci√≥n b√°sicas:\n",
    "- .sum() - Suma valores num√©ricos en cada grupo\n",
    "- .mean() - Calcula la media aritm√©tica de cada grupo\n",
    "- .count() - Cuenta valores no nulos en cada grupo\n",
    "- .size() - Cuenta el total de elementos en cada grupo (incluyendo NaN)\n",
    "- .min() - Encuentra el valor m√≠nimo en cada grupo\n",
    "- .max() - Encuentra el valor m√°ximo en cada grupo\n",
    "\n",
    "### M√©todos de agregaci√≥n avanzada:\n",
    "- .agg() - Aplica m√∫ltiples funciones de agregaci√≥n simult√°neamente\n",
    "- .apply() - Aplica funciones personalizadas a cada grupo\n",
    "- .transform() - Aplica transformaciones manteniendo la forma original del DataFrame\n",
    "\n",
    "### M√©todos de manipulaci√≥n de resultados:\n",
    "- .reset_index() - Convierte √≠ndices de grupo en columnas regulares\n",
    "- .sort_values() - Ordena los resultados agrupados por valores espec√≠ficos\n",
    "- .head() - Muestra los primeros registros de cada grupo\n",
    "\n",
    "### Funci√≥n de salida:\n",
    "- print() - Muestra informaci√≥n sobre grupos y resultados de agregaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fea5c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Agrupaci√≥n b√°sica por una columna:\n",
    "grupos_genero = df.groupby('genre')\n",
    "print(grupos_genero.sum())\n",
    "\n",
    "# Agrupaci√≥n por m√∫ltiples columnas:\n",
    "grupos_multiples = df.groupby(['genre', 'artist'])\n",
    "print(grupos_multiples.mean())\n",
    "\n",
    "# Aplicaci√≥n de m√∫ltiples funciones de agregaci√≥n:\n",
    "resultado = df.groupby('genre').agg({\n",
    "    'plays': ['sum', 'mean', 'count'],\n",
    "    'duration': ['min', 'max']\n",
    "})\n",
    "\n",
    "# Agrupaci√≥n con transformaci√≥n:\n",
    "df['plays_normalized'] = df.groupby('genre')['plays'].transform('mean')\n",
    "\n",
    "# Filtrado de grupos:\n",
    "grupos_grandes = df.groupby('genre').filter(lambda x: len(x) > 100)\n",
    "\n",
    "# Obtener un grupo espec√≠fico:\n",
    "rock_songs = df.groupby('genre').get_group('Rock')\n",
    "\n",
    "# Agrupaci√≥n con ordenamiento:\n",
    "top_genres = df.groupby('genre')['plays'].sum().sort_values(ascending=False)\n",
    "\n",
    "# Aplicar funci√≥n personalizada:\n",
    "def calcular_estadisticas(grupo):\n",
    "    return grupo['plays'].std()\n",
    "\n",
    "estadisticas = df.groupby('genre').apply(calcular_estadisticas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8336a5",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Objeto GroupBy - Estructura que contiene los datos agrupados y permite aplicar operaciones\n",
    "- Agrupaci√≥n simple - Agrupar por una sola columna categ√≥rica\n",
    "- Agrupaci√≥n m√∫ltiple - Crear grupos usando combinaciones de m√∫ltiples columnas\n",
    "- Funciones de agregaci√≥n - Operaciones que resumen datos de cada grupo en un solo valor\n",
    "- Transformaci√≥n de grupos - Aplicar operaciones que mantienen el tama√±o original del DataFrame\n",
    "- Filtrado de grupos - Seleccionar grupos que cumplen criterios espec√≠ficos\n",
    "- √çndices jer√°rquicos - Estructura de √≠ndices multinivel resultante de agrupaciones m√∫ltiples\n",
    "- Reset de √≠ndices - Convertir √≠ndices de grupo en columnas regulares para facilitar el an√°lisis\n",
    "- Funciones personalizadas - Crear y aplicar operaciones espec√≠ficas usando apply()\n",
    "- An√°lisis estad√≠stico por categor√≠as - Generar m√©tricas descriptivas para cada grupo de datos\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øC√≥mo decidir√≠as qu√© columnas usar para agrupar tus datos y qu√© funciones de agregaci√≥n aplicar seg√∫n el tipo de an√°lisis que necesitas realizar, considerando tanto la naturaleza de tus datos como los objetivos de tu investigaci√≥n?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cb86e2",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Ordenar datos\n",
    "Este cap√≠tulo introduce las t√©cnicas de ordenamiento de datos, una habilidad fundamental para organizar y analizar informaci√≥n de manera efectiva en DataFrames. Se enfoca en:\n",
    "\n",
    "- Ordenamiento por una columna\n",
    "    - Organizar los datos de forma ascendente o descendente bas√°ndose en los valores de una columna espec√≠fica\n",
    "- Ordenamiento por m√∫ltiples columnas\n",
    "    - Aplicar criterios de ordenamiento jer√°rquicos utilizando varias columnas con diferentes prioridades\n",
    "- Configuraci√≥n de par√°metros de ordenamiento\n",
    "    - Controlar la direcci√≥n del ordenamiento y el manejo de valores ausentes durante el proceso\n",
    "- Ordenamiento por √≠ndice\n",
    "    - Organizar los datos bas√°ndose en los valores del √≠ndice del DataFrame en lugar de las columnas\n",
    "- Preservaci√≥n y modificaci√≥n de datos\n",
    "    - Decidir si crear una nueva copia ordenada o modificar el DataFrame original directamente\n",
    "- Manejo de valores ausentes en ordenamiento\n",
    "    - Controlar la posici√≥n de los valores NaN en los resultados ordenados\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "### Importaci√≥n de librer√≠as:\n",
    "- import pandas as pd - Importa la librer√≠a pandas para manipulaci√≥n de datos\n",
    "\n",
    "### M√©todos de ordenamiento por columnas:\n",
    "- .sort_values() - Ordena el DataFrame por los valores de una o m√°s columnas\n",
    "- by= - Par√°metro que especifica la columna o columnas por las cuales ordenar\n",
    "- ascending= - Par√°metro que controla la direcci√≥n del ordenamiento (True/False)\n",
    "- inplace= - Par√°metro que aplica cambios directamente al DataFrame original\n",
    "- na_position= - Par√°metro que controla la posici√≥n de valores NaN ('first' o 'last')\n",
    "\n",
    "### M√©todos de ordenamiento por √≠ndice:\n",
    "- .sort_index() - Ordena el DataFrame por los valores del √≠ndice\n",
    "- ascending= - Controla si el ordenamiento es ascendente o descendente\n",
    "\n",
    "### Funci√≥n de salida:\n",
    "- print() - Muestra los resultados del ordenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3f2b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Ordenamiento ascendente por una columna:\n",
    "df_sorted = df.sort_values(by='column_name')\n",
    "\n",
    "# Ordenamiento descendente por una columna:\n",
    "df_sorted = df.sort_values(by='column_name', ascending=False)\n",
    "\n",
    "# Ordenamiento por m√∫ltiples columnas:\n",
    "df_sorted = df.sort_values(by=['column1', 'column2'])\n",
    "\n",
    "# Ordenamiento con diferentes direcciones para m√∫ltiples columnas:\n",
    "df_sorted = df.sort_values(by=['column1', 'column2'], ascending=[True, False])\n",
    "\n",
    "# Ordenamiento modificando el DataFrame original:\n",
    "df.sort_values(by='column_name', inplace=True)\n",
    "\n",
    "# Ordenamiento controlando posici√≥n de valores NaN:\n",
    "df_sorted = df.sort_values(by='column_name', na_position='first')\n",
    "\n",
    "# Ordenamiento por √≠ndice:\n",
    "df_sorted = df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c0bbf4",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Ordenamiento ascendente - Organizar valores de menor a mayor (A-Z, 0-9)\n",
    "- Ordenamiento descendente - Organizar valores de mayor a menor (Z-A, 9-0)\n",
    "- Ordenamiento jer√°rquico - Aplicar m√∫ltiples criterios de ordenamiento con prioridades\n",
    "- Par√°metro by - Especifica las columnas que servir√°n como criterio de ordenamiento\n",
    "- Par√°metro ascending - Lista de valores booleanos para controlar direcci√≥n por columna\n",
    "- Par√°metro na_position - Controla si los valores NaN aparecen al inicio ('first') o final ('last')\n",
    "- Modificaci√≥n inplace - Cambiar el DataFrame original sin crear una copia nueva\n",
    "- Ordenamiento por √≠ndice - Organizar filas bas√°ndose en los valores del √≠ndice del DataFrame\n",
    "- Criterios m√∫ltiples - Usar varias columnas donde la segunda act√∫a como desempate de la primera\n",
    "- Estabilidad del ordenamiento - Mantener el orden relativo de elementos iguales durante el proceso\n",
    "- Tipos de datos mixtos - Manejar el ordenamiento cuando las columnas contienen diferentes tipos de datos\n",
    "- Performance del ordenamiento - Considerar el impacto en memoria y tiempo de procesamiento\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øC√≥mo determinar√≠as el orden de prioridad al usar m√∫ltiples columnas para ordenar tus datos, y en qu√© situaciones ser√≠a m√°s conveniente ordenar por √≠ndice en lugar de por valores de columnas espec√≠ficas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e165d00",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Contar valores ausentes\n",
    "Este cap√≠tulo introduce el conteo de valores ausentes, una t√©cnica fundamental para evaluar la calidad y completitud de los datos en datasets. Se enfoca en:\n",
    "\n",
    "- Identificaci√≥n de valores ausentes\n",
    "    - Detectar la presencia de valores NaN, None y otros tipos de valores faltantes en el dataset utilizando m√©todos especializados\n",
    "- Cuantificaci√≥n de valores ausentes\n",
    "    - Contar la cantidad exacta de valores faltantes por columna y en todo el dataset para evaluar el impacto\n",
    "- An√°lisis de patrones de ausencia\n",
    "    - Identificar qu√© columnas tienen m√°s valores ausentes y evaluar si existe un patr√≥n en los datos faltantes\n",
    "- Evaluaci√≥n de completitud de datos\n",
    "    - Calcular porcentajes de valores ausentes para determinar la calidad general del dataset\n",
    "- Visualizaci√≥n de valores ausentes\n",
    "    - Presentar la informaci√≥n de valores faltantes de manera clara y comprensible para tomar decisiones informadas\n",
    "- Preparaci√≥n para tratamiento\n",
    "    - Establecer las bases para decidir estrategias de manejo de valores ausentes (eliminaci√≥n, imputaci√≥n, etc.)\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "### Importaci√≥n de librer√≠as:\n",
    "- import pandas as pd - Importa la librer√≠a pandas para manipulaci√≥n de datos\n",
    "\n",
    "### Carga de datos:\n",
    "- pd.read_csv() - Lee archivos CSV y carga los datos en un DataFrame\n",
    "\n",
    "### M√©todos de identificaci√≥n de valores ausentes:\n",
    "- .isnull() - Identifica valores ausentes devolviendo True/False para cada celda\n",
    "- .isna() - M√©todo alternativo para identificar valores ausentes (equivalente a isnull())\n",
    "- .notnull() - Identifica valores NO ausentes devolviendo True/False\n",
    "- .notna() - M√©todo alternativo para identificar valores NO ausentes\n",
    "\n",
    "### M√©todos de conteo de valores ausentes:\n",
    "- .isnull().sum() - Cuenta valores ausentes por columna\n",
    "- .isna().sum() - M√©todo alternativo para contar valores ausentes por columna\n",
    "- .isnull().sum().sum() - Cuenta el total de valores ausentes en todo el DataFrame\n",
    "\n",
    "### M√©todos de informaci√≥n del DataFrame:\n",
    "- .info() - Proporciona informaci√≥n general incluyendo valores no nulos por columna\n",
    "- .shape - Muestra las dimensiones del DataFrame (filas, columnas)\n",
    "- .describe() - Estad√≠sticas descriptivas que pueden revelar patrones de ausencia\n",
    "\n",
    "### Funci√≥n de salida:\n",
    "- print() - Muestra informaci√≥n sobre valores ausentes y resultados del conteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8032af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Conteo de valores ausentes por columna:\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Conteo total de valores ausentes:\n",
    "print(df.isnull().sum().sum())\n",
    "\n",
    "# Verificaci√≥n de valores ausentes en columna espec√≠fica:\n",
    "print(df['columna'].isnull().sum())\n",
    "\n",
    "# Porcentaje de valores ausentes por columna:\n",
    "print((df.isnull().sum() / len(df)) * 100)\n",
    "\n",
    "# Informaci√≥n general del DataFrame:\n",
    "print(df.info())\n",
    "\n",
    "# Verificaci√≥n de completitud:\n",
    "print(f\"Total de celdas: {df.shape[0] * df.shape[1]}\")\n",
    "print(f\"Valores ausentes: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9446b81",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Valores ausentes\n",
    "- Datos faltantes representados como NaN, None o valores vac√≠os\n",
    "- M√©todos isnull() e isna()\n",
    "- Funciones equivalentes para detectar valores ausentes\n",
    "- Conteo por columna\n",
    "- Identificar qu√© variables tienen m√°s datos faltantes\n",
    "- Conteo total\n",
    "- Evaluar la magnitud general de valores ausentes en todo el dataset\n",
    "- Porcentaje de ausencia\n",
    "- Calcular la proporci√≥n de valores faltantes respecto al total\n",
    "- An√°lisis de completitud\n",
    "- Evaluar qu√© tan completo est√° el dataset para el an√°lisis\n",
    "- Patrones de ausencia\n",
    "- Identificar si los valores faltantes siguen alg√∫n patr√≥n espec√≠fico\n",
    "- Informaci√≥n del DataFrame\n",
    "- Usar info() para obtener un resumen de valores no nulos\n",
    "- Evaluaci√≥n de calidad\n",
    "- Determinar si el dataset es adecuado para el an√°lisis planificado\n",
    "- Preparaci√≥n para limpieza\n",
    "- Establecer criterios para decidir el tratamiento de valores ausentes\n",
    "- M√©todos complementarios\n",
    "- Usar notnull() y notna() para verificar valores presentes\n",
    "- Dimensiones del dataset\n",
    "- Relacionar el conteo de ausentes con el tama√±o total de datos\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øQu√© porcentaje de valores ausentes considerar√≠as aceptable en una columna antes de decidir eliminarla del an√°lisis, y c√≥mo influir√≠a la importancia de esa variable en tu decisi√≥n sobre el tratamiento de los datos faltantes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7613ca9b",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Filtrar DataFrames por valores ausentes\n",
    "Este cap√≠tulo introduce el filtrado de DataFrames por valores ausentes, una t√©cnica fundamental para seleccionar y analizar subconjuntos de datos bas√°ndose en la presencia o ausencia de valores. Se enfoca en:\n",
    "\n",
    "- Filtrado por filas con valores ausentes\n",
    "    - Seleccionar filas que contienen valores NaN en columnas espec√≠ficas o en cualquier columna del DataFrame\n",
    "- Filtrado por filas sin valores ausentes\n",
    "    - Identificar y extraer √∫nicamente las filas que tienen datos completos en todas las columnas relevantes\n",
    "- Filtrado condicional por ausencias\n",
    "    - Aplicar criterios espec√≠ficos para filtrar datos bas√°ndose en patrones de valores ausentes en m√∫ltiples columnas\n",
    "- An√°lisis de subconjuntos de datos\n",
    "    - Examinar caracter√≠sticas espec√≠ficas de los datos que tienen o no tienen valores ausentes\n",
    "- Combinaci√≥n de filtros\n",
    "    - Crear filtros complejos que combinen condiciones de valores ausentes con otros criterios de selecci√≥n\n",
    "- Evaluaci√≥n de calidad por segmentos\n",
    "    - Analizar la completitud de datos en diferentes subconjuntos del DataFrame\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "### Importaci√≥n de librer√≠as:\n",
    "- import pandas as pd - Importa la librer√≠a pandas para manipulaci√≥n de datos\n",
    "\n",
    "### Carga de datos:\n",
    "- pd.read_csv() - Lee archivos CSV y carga los datos en un DataFrame\n",
    "\n",
    "### M√©todos de identificaci√≥n de valores ausentes:\n",
    "- .isnull() - Identifica valores ausentes devolviendo True/False para cada celda\n",
    "- .isna() - M√©todo alternativo para identificar valores ausentes\n",
    "- .notnull() - Identifica valores NO ausentes devolviendo True/False\n",
    "- .notna() - M√©todo alternativo para identificar valores NO ausentes\n",
    "\n",
    "### M√©todos de filtrado por valores ausentes:\n",
    "- df[df['columna'].isnull()] - Filtra filas donde la columna espec√≠fica tiene valores ausentes\n",
    "- df[df['columna'].isna()] - M√©todo alternativo para filtrar por valores ausentes\n",
    "- df[df['columna'].notnull()] - Filtra filas donde la columna espec√≠fica NO tiene valores ausentes\n",
    "- df[df['columna'].notna()] - M√©todo alternativo para filtrar por valores NO ausentes\n",
    "\n",
    "### M√©todos de filtrado m√∫ltiple:\n",
    "- df[df.isnull().any(axis=1)] - Filtra filas que tienen al menos un valor ausente\n",
    "- df[df.notnull().all(axis=1)] - Filtra filas que NO tienen ning√∫n valor ausente\n",
    "- df[df[['col1', 'col2']].isnull().any(axis=1)] - Filtra por valores ausentes en columnas espec√≠ficas\n",
    "\n",
    "### Operadores l√≥gicos para filtrado:\n",
    "- & - Operador AND para combinar condiciones\n",
    "- | - Operador OR para combinar condiciones\n",
    "- ~ - Operador NOT para negar condiciones\n",
    "\n",
    "### M√©todos de informaci√≥n del DataFrame:\n",
    "- .shape - Muestra las dimensiones del DataFrame filtrado\n",
    "- .info() - Proporciona informaci√≥n general sobre el DataFrame filtrado\n",
    "\n",
    "### Funci√≥n de salida:\n",
    "- print() - Muestra informaci√≥n sobre los resultados del filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d429061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Filtrar filas con valores ausentes en una columna espec√≠fica:\n",
    "filas_con_ausentes = df[df['columna'].isnull()]\n",
    "\n",
    "# Filtrar filas sin valores ausentes en una columna espec√≠fica:\n",
    "filas_completas = df[df['columna'].notnull()]\n",
    "\n",
    "# Filtrar filas que tienen al menos un valor ausente:\n",
    "filas_con_cualquier_ausente = df[df.isnull().any(axis=1)]\n",
    "\n",
    "# Filtrar filas completamente sin valores ausentes:\n",
    "filas_completamente_llenas = df[df.notnull().all(axis=1)]\n",
    "\n",
    "# Filtrar usando operador de negaci√≥n:\n",
    "filas_sin_ausentes = df[~df['columna'].isnull()]\n",
    "\n",
    "# Filtrar con m√∫ltiples condiciones:\n",
    "filtro_complejo = df[df['col1'].isnull() & df['col2'].notnull()]\n",
    "\n",
    "# Verificar el tama√±o despu√©s del filtrado:\n",
    "print(f\"Filas originales: {df.shape[0]}\")\n",
    "print(f\"Filas con ausentes: {df[df['columna'].isnull()].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dcc422",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Filtrado booleano - Usar m√°scaras de True/False para seleccionar filas espec√≠ficas\n",
    "- Operador de negaci√≥n (~) - Invertir condiciones booleanas para obtener el resultado opuesto\n",
    "- Filtrado por columna espec√≠fica - Seleccionar filas bas√°ndose en valores ausentes en una columna particular\n",
    "- Filtrado por m√∫ltiples columnas - Usar any() y all() para evaluar condiciones en varias columnas\n",
    "- Combinaci√≥n de condiciones - Usar operadores l√≥gicos (&, |) para crear filtros complejos\n",
    "- M√°scaras booleanas - Series de valores True/False que determinan qu√© filas seleccionar\n",
    "- M√©todo any() - Eval√∫a si al menos una condici√≥n es verdadera en el eje especificado\n",
    "- M√©todo all() - Eval√∫a si todas las condiciones son verdaderas en el eje especificado\n",
    "- An√°lisis de subconjuntos - Examinar caracter√≠sticas espec√≠ficas de datos filtrados\n",
    "- Evaluaci√≥n de completitud - Determinar qu√© porci√≥n de datos est√° completa o incompleta\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øEn qu√© situaciones ser√≠a m√°s √∫til analizar √∫nicamente las filas con valores ausentes versus las filas con datos completos, y c√≥mo podr√≠a influir esto en las conclusiones de tu an√°lisis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ef7942",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Rellenar los valores categ√≥ricos ausentes\n",
    "Este cap√≠tulo introduce el relleno de valores categ√≥ricos ausentes, una t√©cnica fundamental para manejar datos faltantes en variables no num√©ricas y garantizar la completitud del an√°lisis. Se enfoca en:\n",
    "\n",
    "- Diferenciaci√≥n entre variables cuantitativas y categ√≥ricas\n",
    "    - Distinguir entre datos num√©ricos que permiten operaciones aritm√©ticas y datos categ√≥ricos que representan categor√≠as o etiquetas\n",
    "- Identificaci√≥n de variables categ√≥ricas\n",
    "    - Reconocer columnas que contienen valores como texto, c√≥digos, etiquetas o categor√≠as que no requieren c√°lculos matem√°ticos\n",
    "- M√©todos de relleno con par√°metros de lectura\n",
    "    - Aplicar t√©cnicas para controlar c√≥mo se interpretan los valores ausentes durante la carga de datos\n",
    "- Reemplazo de valores categ√≥ricos\n",
    "    - Usar m√©todos para sustituir valores ausentes o vac√≠os con categor√≠as apropiadas\n",
    "- An√°lisis de tasas de conversi√≥n\n",
    "    - Calcular m√©tricas de negocio utilizando datos categ√≥ricos limpios para obtener insights significativos\n",
    "- Agrupaci√≥n y an√°lisis por categor√≠as\n",
    "    - Usar groupby() para analizar datos categ√≥ricos y calcular estad√≠sticas por grupos espec√≠ficos\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "### Importaci√≥n de librer√≠as:\n",
    "- import pandas as pd - Importa la librer√≠a pandas para manipulaci√≥n de datos\n",
    "\n",
    "### Carga de datos:\n",
    "- pd.read_csv() - Lee archivos CSV y carga los datos en un DataFrame\n",
    "- keep_default_na=False - Par√°metro que convierte valores ausentes en cadenas vac√≠as durante la lectura\n",
    "\n",
    "### M√©todos de identificaci√≥n de valores ausentes:\n",
    "- .info() - Proporciona informaci√≥n general sobre el DataFrame incluyendo valores no nulos\n",
    "- .head() - Muestra las primeras filas del DataFrame\n",
    "\n",
    "### M√©todos de reemplazo de valores:\n",
    "- .replace() - Reemplaza valores espec√≠ficos con otros valores\n",
    "- .replace('', 'email') - Reemplaza cadenas vac√≠as con la categor√≠a 'email'\n",
    "\n",
    "### M√©todos de agrupaci√≥n y an√°lisis:\n",
    "- .groupby() - Agrupa datos por una o m√°s columnas categ√≥ricas\n",
    "- .count() - Cuenta el n√∫mero de valores no nulos en cada grupo\n",
    "- .sum() - Suma valores num√©ricos dentro de cada grupo\n",
    "\n",
    "### Funci√≥n de salida:\n",
    "- print() - Muestra informaci√≥n sobre el procesamiento y resultados del an√°lisis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544cf7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Lectura de datos convirtiendo valores ausentes en cadenas vac√≠as:\n",
    "import pandas as pd\n",
    "df_logs = pd.read_csv('/datasets/visit_log.csv', keep_default_na=False)\n",
    "print(df_logs.head())\n",
    "df_logs.info()\n",
    "\n",
    "# Reemplazo de cadenas vac√≠as con categor√≠a espec√≠fica:\n",
    "df_logs['source'] = df_logs['source'].replace('', 'email')\n",
    "\n",
    "# Conteo de visitas por fuente de tr√°fico:\n",
    "visits = df_logs.groupby('source')['user_id'].count()\n",
    "\n",
    "# C√°lculo de compras por fuente:\n",
    "purchases = df_logs.groupby('source')['purchase'].sum()\n",
    "print(purchases)\n",
    "\n",
    "# C√°lculo de tasa de conversi√≥n:\n",
    "conversion = purchases / visits\n",
    "print(conversion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9188f4b",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Valores categ√≥ricos ausentes - Datos faltantes en variables que representan categor√≠as o grupos discretos\n",
    "- Par√°metro keep_default_na=False - Configuraci√≥n para leer cadenas vac√≠as como texto en lugar de NaN\n",
    "- Relleno con moda - Usar el valor m√°s frecuente para completar datos categ√≥ricos ausentes\n",
    "- Relleno con valor constante - Asignar un valor espec√≠fico predefinido a todos los datos ausentes\n",
    "- An√°lisis de frecuencias - Examinar la distribuci√≥n de valores categ√≥ricos antes del relleno\n",
    "- Preservaci√≥n de distribuci√≥n - Mantener las proporciones originales al completar datos ausentes\n",
    "- Estrategias de relleno categ√≥rico - Diferentes enfoques para manejar ausencias en variables categ√≥ricas\n",
    "- Validaci√≥n post-relleno - Verificar que no queden valores ausentes despu√©s del procesamiento\n",
    "- Impacto en an√°lisis - Evaluar c√≥mo el relleno de categ√≥ricos afecta los resultados posteriores\n",
    "- Selecci√≥n de estrategia - Elegir el m√©todo de relleno m√°s apropiado seg√∫n el contexto de los datos\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øCu√°ndo ser√≠a m√°s apropiado rellenar valores categ√≥ricos ausentes con la moda versus usar un valor constante como \"unknown\", y c√≥mo podr√≠a cada estrategia afectar las conclusiones de tu an√°lisis?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd80ee1",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Rellenar los valores ausentes cuantitativos\n",
    "Este cap√≠tulo introduce el manejo de valores cuantitativos ausentes, una t√©cnica fundamental para completar datos faltantes en variables num√©ricas y preservar la integridad estad√≠stica del an√°lisis. Se enfoca en:\n",
    "\n",
    "- Identificaci√≥n de valores cuantitativos ausentes\n",
    "    - Detectar valores NaN o ausentes espec√≠ficamente en columnas num√©ricas utilizando m√©todos de exploraci√≥n estad√≠stica\n",
    "- Estrategias de relleno num√©rico\n",
    "    - Aplicar t√©cnicas estad√≠sticas apropiadas para completar valores cuantitativos como la media, mediana o m√©todos de interpolaci√≥n\n",
    "- An√°lisis de distribuci√≥n num√©rica\n",
    "    - Evaluar la distribuci√≥n estad√≠stica de los datos cuantitativos para elegir la medida de tendencia central m√°s apropiada\n",
    "- Preservaci√≥n de propiedades estad√≠sticas\n",
    "    - Mantener las caracter√≠sticas estad√≠sticas originales de los datos al rellenar valores ausentes\n",
    "- Consideraci√≥n de outliers\n",
    "    - Evaluar el impacto de valores at√≠picos en la elecci√≥n del m√©todo de relleno m√°s adecuado\n",
    "- Validaci√≥n estad√≠stica\n",
    "    - Verificar que el relleno de valores cuantitativos no altere significativamente las propiedades estad√≠sticas del dataset\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "\n",
    "### Importaci√≥n de librer√≠as:\n",
    "- import pandas as pd - Importa la librer√≠a pandas para manipulaci√≥n de datos\n",
    "\n",
    "### Carga de datos:\n",
    "- pd.read_csv() - Lee archivos CSV y carga los datos en un DataFrame\n",
    "\n",
    "### M√©todos de identificaci√≥n de valores ausentes:\n",
    "- .isna() - Identifica valores ausentes devolviendo True/False para cada celda\n",
    "- .isna().sum() - Cuenta el n√∫mero total de valores ausentes por columna\n",
    "- .info() - Muestra informaci√≥n general incluyendo valores no nulos\n",
    "\n",
    "### M√©todos de an√°lisis estad√≠stico:\n",
    "- .mean() - Calcula la media aritm√©tica de una columna num√©rica\n",
    "- .median() - Calcula la mediana de una columna num√©rica\n",
    "- .mode() - Calcula la moda de una columna num√©rica\n",
    "- .describe() - Proporciona estad√≠sticas descriptivas completas\n",
    "- .std() - Calcula la desviaci√≥n est√°ndar\n",
    "- .min() - Obtiene el valor m√≠nimo\n",
    "- .max() - Obtiene el valor m√°ximo\n",
    "\n",
    "### M√©todos de relleno de valores ausentes:\n",
    "- .fillna() - Rellena valores ausentes con un valor espec√≠fico\n",
    "- .fillna(df['columna'].mean()) - Rellena con la media de la columna\n",
    "- .fillna(df['columna'].median()) - Rellena con la mediana de la columna\n",
    "- .fillna(method='ffill') - Rellena con el valor anterior (forward fill)\n",
    "- .fillna(method='bfill') - Rellena con el valor siguiente (backward fill)\n",
    "- .interpolate() - Rellena usando interpolaci√≥n lineal\n",
    "- inplace=True - Par√°metro que aplica cambios directamente al DataFrame\n",
    "\n",
    "### M√©todos de verificaci√≥n:\n",
    "- .shape - Muestra las dimensiones del DataFrame (filas, columnas)\n",
    "- .head() - Muestra las primeras filas del DataFrame\n",
    "- .tail() - Muestra las √∫ltimas filas del DataFrame\n",
    "\n",
    "### Funci√≥n de salida:\n",
    "- print() - Muestra informaci√≥n sobre valores ausentes y resultados del relleno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e33739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# C√°lculo de la media para rellenar valores ausentes:\n",
    "age_avg = analytics_data['age'].mean()\n",
    "print(\"Mean age:\", age_avg)\n",
    "analytics_data['age'] = analytics_data['age'].fillna(age_avg)\n",
    "\n",
    "# Filtrado por tipo de dispositivo:\n",
    "desktop_data = analytics_data[analytics_data['device_type'] == 'desktop']\n",
    "mobile_data = analytics_data[analytics_data['device_type'] == 'mobile']\n",
    "\n",
    "# C√°lculo de medias espec√≠ficas por grupo:\n",
    "desktop_avg = desktop_data['time'].mean()\n",
    "mobile_avg = mobile_data['time'].mean()\n",
    "\n",
    "# Relleno con medias espec√≠ficas por grupo:\n",
    "desktop_data['time'].fillna(desktop_avg, inplace=True)\n",
    "mobile_data['time'].fillna(mobile_avg, inplace=True)\n",
    "\n",
    "# Verificaci√≥n de informaci√≥n del DataFrame:\n",
    "analytics_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e7801",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Variables cuantitativas vs categ√≥ricas - Distinci√≥n entre datos num√©ricos (edad, tiempo) y categ√≥ricos (user_id, device_type)\n",
    "- Media aritm√©tica - Suma de todos los valores dividida entre el n√∫mero total de valores para representar el valor t√≠pico\n",
    "- Mediana - Valor central cuando los datos se ordenan de menor a mayor, √∫til cuando hay valores at√≠picos\n",
    "- Valores at√≠picos (outliers) - Datos que se desv√≠an significativamente del patr√≥n general y afectan la representatividad de la media\n",
    "- Selecci√≥n de medida de tendencia central - Criterios para elegir entre media y mediana seg√∫n la presencia de outliers\n",
    "- Relleno con valores representativos - Uso de estad√≠sticas descriptivas apropiadas para completar datos cuantitativos ausentes\n",
    "- Filtrado por grupos - Separaci√≥n de datos por categor√≠as para calcular estad√≠sticas espec√≠ficas por subgrupo\n",
    "- Exclusi√≥n autom√°tica de NaN - Los m√©todos estad√≠sticos como mean() ignoran autom√°ticamente los valores ausentes en sus c√°lculos\n",
    "- Unidades de medida - Importancia de considerar las unidades (a√±os, segundos) al trabajar con datos cuantitativos\n",
    "- An√°lisis previo de outliers - Necesidad de verificar la presencia de valores at√≠picos antes de elegir el m√©todo de relleno\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øEn qu√© situaciones ser√≠a m√°s apropiado usar la mediana en lugar de la media para rellenar valores cuantitativos ausentes, y c√≥mo podr√≠as identificar si tu conjunto de datos tiene valores at√≠picos que influyan en esta decisi√≥n?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41459529",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Gesti√≥n de duplicados\n",
    "Este cap√≠tulo introduce la gesti√≥n de duplicados, una t√©cnica fundamental para identificar y manejar registros repetidos en datasets y garantizar la calidad del an√°lisis. Se enfoca en:\n",
    "\n",
    "- Identificaci√≥n de registros duplicados\n",
    "    - Detectar filas completamente id√©nticas o duplicadas en columnas espec√≠ficas utilizando m√©todos especializados\n",
    "- Comprensi√≥n de tipos de duplicados\n",
    "    - Distinguir entre duplicados completos (toda la fila) y duplicados parciales (columnas espec√≠ficas) seg√∫n el contexto del an√°lisis\n",
    "- Estrategias de eliminaci√≥n de duplicados\n",
    "    - Aplicar m√©todos para remover registros duplicados manteniendo solo la primera o √∫ltima ocurrencia seg√∫n sea necesario\n",
    "- An√°lisis de impacto de duplicados\n",
    "    - Evaluar c√≥mo los registros duplicados afectan la integridad y representatividad de los datos\n",
    "- Preservaci√≥n de registros √∫nicos\n",
    "    - Mantener solo los registros √∫nicos relevantes mientras se eliminan las copias innecesarias\n",
    "- Control de criterios de duplicaci√≥n\n",
    "    - Especificar qu√© columnas considerar para determinar si un registro es duplicado\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "\n",
    "### Importaci√≥n de librer√≠as:\n",
    "- import pandas as pd - Importa la librer√≠a pandas para manipulaci√≥n de datos\n",
    "\n",
    "### Carga de datos:\n",
    "- pd.read_csv() - Lee archivos CSV y carga los datos en un DataFrame\n",
    "\n",
    "### M√©todos de identificaci√≥n de duplicados:\n",
    "- .duplicated() - Identifica filas duplicadas devolviendo True/False para cada fila\n",
    "- .duplicated().sum() - Cuenta el n√∫mero total de duplicados cuando se combina con duplicated()\n",
    "- subset= - Par√°metro que especifica columnas espec√≠ficas para evaluar duplicaci√≥n\n",
    "\n",
    "### M√©todos de eliminaci√≥n de duplicados:\n",
    "- .drop_duplicates() - Elimina filas duplicadas del DataFrame\n",
    "- .drop_duplicates(keep='first') - Elimina duplicados manteniendo la primera ocurrencia\n",
    "- .drop_duplicates(keep='last') - Elimina duplicados manteniendo la √∫ltima ocurrencia\n",
    "- .drop_duplicates(keep=False) - Elimina todas las ocurrencias de duplicados\n",
    "- .drop_duplicates(subset=['columna']) - Elimina duplicados bas√°ndose en columnas espec√≠ficas\n",
    "- inplace=True - Par√°metro que aplica cambios directamente al DataFrame\n",
    "\n",
    "### M√©todos de reindexaci√≥n:\n",
    "- .reset_index() - Reinicia los √≠ndices del DataFrame\n",
    "- .reset_index(drop=True) - Reinicia los √≠ndices eliminando el √≠ndice anterior\n",
    "\n",
    "### M√©todos de an√°lisis de valores √∫nicos:\n",
    "- .unique() - Obtiene los valores √∫nicos de una columna espec√≠fica\n",
    "- .nunique() - Cuenta el n√∫mero de valores √∫nicos en una columna\n",
    "\n",
    "### M√©todos de informaci√≥n del DataFrame:\n",
    "- .shape - Muestra las dimensiones del DataFrame (filas, columnas)\n",
    "- .info() - Proporciona informaci√≥n general sobre el DataFrame\n",
    "\n",
    "### Funci√≥n de salida:\n",
    "- print() - Muestra informaci√≥n sobre duplicados y resultados del procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3962070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Eliminaci√≥n de duplicados completos:\n",
    "df_clean = df.drop_duplicates()\n",
    "\n",
    "# Eliminaci√≥n de duplicados en columnas espec√≠ficas:\n",
    "df_clean = df.drop_duplicates(subset=['track', 'artist'])\n",
    "\n",
    "# Eliminaci√≥n manteniendo el √∫ltimo duplicado:\n",
    "df_last = df.drop_duplicates(keep='last')\n",
    "\n",
    "# Eliminaci√≥n usando inplace:\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Verificaci√≥n del tama√±o antes y despu√©s:\n",
    "print(f\"Antes: {df.shape}\")\n",
    "df_clean = df.drop_duplicates()\n",
    "print(f\"Despu√©s: {df_clean.shape}\")\n",
    "\n",
    "# Reinicio de √≠ndices despu√©s de eliminar duplicados:\n",
    "df_clean = df_clean.reset_index(drop=True)\n",
    "\n",
    "# An√°lisis de valores √∫nicos:\n",
    "print(df['columna'].unique())\n",
    "print(df['columna'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603c8884",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Duplicados completos - Filas que son id√©nticas en todas sus columnas\n",
    "- Duplicados parciales - Filas que son id√©nticas solo en columnas espec√≠ficas definidas por subset\n",
    "- Par√°metro keep - Controla qu√© duplicado mantener: 'first' (primero), 'last' (√∫ltimo), False (eliminar todos)\n",
    "- Par√°metro subset - Define qu√© columnas considerar para determinar duplicaci√≥n\n",
    "- An√°lisis de impacto - Evaluar c√≥mo los duplicados afectan el tama√±o y representatividad del dataset\n",
    "- Verificaci√≥n de duplicados - Usar duplicated() para identificar la presencia y cantidad de registros duplicados\n",
    "- Estrategia de conservaci√≥n - Decidir qu√© instancia del duplicado mantener seg√∫n el contexto del an√°lisis\n",
    "- Limpieza de datos - Proceso de eliminaci√≥n de duplicados como parte de la preparaci√≥n de datos\n",
    "- Modificaci√≥n inplace - Aplicar cambios de eliminaci√≥n directamente al DataFrame original\n",
    "- Reindexaci√≥n post-eliminaci√≥n - Reorganizar los √≠ndices despu√©s de eliminar filas duplicadas\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øC√≥mo determinar√≠as qu√© columnas espec√≠ficas considerar al identificar duplicados en tu dataset, y cu√°ndo ser√≠a apropiado mantener el primer duplicado versus el √∫ltimo duplicado encontrado?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1ab025",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: √çndices en DataFrames y Series\n",
    "Este cap√≠tulo introduce el manejo de √≠ndices en pandas, una funcionalidad fundamental para organizar, acceder y manipular datos de manera eficiente. Se enfoca en:\n",
    "\n",
    "- Comprensi√≥n de √≠ndices\n",
    "    - Entender qu√© son los √≠ndices y c√≥mo funcionan como etiquetas para filas y columnas en DataFrames y Series\n",
    "- Manipulaci√≥n de √≠ndices\n",
    "    - Modificar, establecer y resetear √≠ndices para optimizar el acceso y organizaci√≥n de los datos\n",
    "- Acceso por √≠ndices\n",
    "    - Utilizar √≠ndices para seleccionar, filtrar y acceder a datos espec√≠ficos de manera eficiente\n",
    "- √çndices personalizados\n",
    "    - Crear √≠ndices significativos que faciliten el an√°lisis y la interpretaci√≥n de los datos\n",
    "- Operaciones con √≠ndices\n",
    "    -Realizar operaciones como ordenamiento, b√∫squeda y alineaci√≥n usando √≠ndices\n",
    "- √çndices jer√°rquicos\n",
    "    - Trabajar con MultiIndex para estructuras de datos m√°s complejas\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "### Importaci√≥n de librer√≠as:\n",
    "- import pandas as pd - Importa la librer√≠a pandas para manipulaci√≥n de datos\n",
    "\n",
    "### Carga de datos:\n",
    "- pd.read_csv() - Lee archivos CSV y carga los datos en un DataFrame\n",
    "\n",
    "### M√©todos de visualizaci√≥n de √≠ndices:\n",
    "- .index - Accede al √≠ndice del DataFrame o Series\n",
    "- .columns - Accede a los nombres de las columnas del DataFrame\n",
    "- .index.name - Obtiene o establece el nombre del √≠ndice\n",
    "\n",
    "### M√©todos de establecimiento de √≠ndices:\n",
    "- .set_index() - Establece una o m√°s columnas como √≠ndice\n",
    "- .set_index('columna') - Establece una columna espec√≠fica como √≠ndice\n",
    "- .set_index(['col1', 'col2']) - Establece m√∫ltiples columnas como √≠ndice (MultiIndex)\n",
    "- inplace=True - Par√°metro que aplica cambios directamente al DataFrame\n",
    "\n",
    "### M√©todos de reseteo de √≠ndices:\n",
    "- .reset_index() - Convierte el √≠ndice en una columna regular\n",
    "- .reset_index(drop=True) - Resetea el √≠ndice eliminando el √≠ndice anterior\n",
    "- .reset_index(inplace=True) - Resetea el √≠ndice modificando el DataFrame original\n",
    "\n",
    "### M√©todos de acceso por √≠ndices:\n",
    "- .loc[] - Acceso por etiquetas de √≠ndice\n",
    "- .iloc[] - Acceso por posici√≥n num√©rica\n",
    "- .at[] - Acceso r√°pido a un valor espec√≠fico por etiqueta\n",
    "- .iat[] - Acceso r√°pido a un valor espec√≠fico por posici√≥n\n",
    "\n",
    "### M√©todos de ordenamiento por √≠ndices:\n",
    "- .sort_index() - Ordena el DataFrame por el √≠ndice\n",
    "- .sort_index(ascending=False) - Ordena el √≠ndice en orden descendente\n",
    "- .sort_values() - Ordena por valores de una columna espec√≠fica\n",
    "\n",
    "### M√©todos de manipulaci√≥n de √≠ndices:\n",
    "- .reindex() - Reordena el DataFrame seg√∫n un nuevo √≠ndice\n",
    "- .rename() - Renombra √≠ndices o columnas\n",
    "- .rename_axis() - Renombra el eje del √≠ndice\n",
    "\n",
    "### M√©todos para MultiIndex:\n",
    "- pd.MultiIndex.from_tuples() - Crea un MultiIndex desde tuplas\n",
    "- pd.MultiIndex.from_arrays() - Crea un MultiIndex desde arrays\n",
    "- .swaplevel() - Intercambia niveles en un MultiIndex\n",
    "- .droplevel() - Elimina un nivel del MultiIndex\n",
    "\n",
    "### M√©todos de informaci√≥n:\n",
    "- .info() - Informaci√≥n general del DataFrame incluyendo √≠ndices\n",
    "- .describe() - Estad√≠sticas descriptivas\n",
    "- .shape - Dimensiones del DataFrame\n",
    "\n",
    "### Funci√≥n de salida:\n",
    "- print() - Muestra informaci√≥n sobre √≠ndices y resultados del procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60016307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Creaci√≥n de DataFrame con √≠ndice personalizado:\n",
    "df = pd.DataFrame({'state': states, 'flower': flowers, 'insect': insects}, index=index)\n",
    "\n",
    "# Establecimiento de √≠ndice desde una columna:\n",
    "df = df.set_index('state')\n",
    "\n",
    "# Eliminaci√≥n del nombre del √≠ndice:\n",
    "df.index.name = None\n",
    "\n",
    "# Acceso con loc[] (por etiquetas):\n",
    "filtered_df = df.loc[['state 1', 'state 3'], ['flower', 'insect']]\n",
    "\n",
    "# Acceso con iloc[] (por posici√≥n):\n",
    "flowers = df.iloc[0:3, 1]\n",
    "\n",
    "# Visualizaci√≥n de informaci√≥n del √≠ndice:\n",
    "print(df.index)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d081589a",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- √çndices personalizados\n",
    "- Establecer etiquetas significativas para las filas usando valores espec√≠ficos\n",
    "- set_index()\n",
    "- Convertir una columna existente en el √≠ndice del DataFrame\n",
    "- Nombres de √≠ndices\n",
    "- Asignar y eliminar nombres descriptivos para los √≠ndices usando index.name\n",
    "- loc[] vs iloc[]\n",
    "- Diferencia entre indexaci√≥n por etiquetas (loc) y por posici√≥n num√©rica (iloc)\n",
    "- Indexaci√≥n m√∫ltiple\n",
    "- Seleccionar m√∫ltiples filas y columnas simult√°neamente\n",
    "- Atributo index\n",
    "- Acceder y manipular directamente el objeto √≠ndice del DataFrame\n",
    "- Filtrado por √≠ndice\n",
    "- Usar valores de √≠ndice para seleccionar subconjuntos espec√≠ficos de datos\n",
    "- Indexaci√≥n booleana\n",
    "- Aplicar condiciones l√≥gicas para filtrar datos bas√°ndose en √≠ndices\n",
    "- Manipulaci√≥n de estructura\n",
    "- Modificar la organizaci√≥n de datos cambiando √≠ndices y columnas\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øEn qu√© situaciones ser√≠a m√°s conveniente usar loc[] versus iloc[] para acceder a tus datos, y c√≥mo puede un √≠ndice personalizado mejorar la legibilidad y eficiencia de tu an√°lisis de datos?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce271ba",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Filtrado personalizado mediante query()\n",
    "Este cap√≠tulo introduce el m√©todo query() de pandas, una herramienta poderosa para filtrar DataFrames usando expresiones de cadena similares a SQL. Se enfoca en:\n",
    "\n",
    "- Sintaxis de consultas con query()\n",
    "    - Utilizar expresiones de cadena para crear filtros complejos de manera m√°s legible y eficiente\n",
    "- Operadores de comparaci√≥n en query()\n",
    "    - Aplicar operadores l√≥gicos y de comparaci√≥n dentro de expresiones de cadena para filtrar datos\n",
    "- Filtrado con m√∫ltiples condiciones\n",
    "    - Combinar m√∫ltiples criterios usando operadores l√≥gicos (and, or, not) en una sola expresi√≥n query()\n",
    "- Variables externas en query()\n",
    "    - Referenciar variables de Python dentro de las expresiones query() usando el s√≠mbolo @\n",
    "- Filtrado con m√©todos de cadena\n",
    "    - Integrar m√©todos de manipulaci√≥n de strings dentro de las expresiones query() para filtros m√°s sofisticados\n",
    "- Optimizaci√≥n de consultas\n",
    "    - Aprovechar la eficiencia del m√©todo query() para mejorar el rendimiento en DataFrames grandes\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "### Importaci√≥n de librer√≠as:\n",
    "- import pandas as pd - Importa la librer√≠a pandas para manipulaci√≥n de datos\n",
    "\n",
    "### Carga de datos:\n",
    "- pd.read_csv() - Lee archivos CSV y carga los datos en un DataFrame\n",
    "\n",
    "### M√©todo principal de filtrado:\n",
    "- .query() - Filtra el DataFrame usando expresiones de cadena\n",
    "- .query('condici√≥n') - Aplica una condici√≥n simple de filtrado\n",
    "- .query('columna > valor') - Filtra usando operadores de comparaci√≥n\n",
    "- .query('columna == \"valor\"') - Filtra por igualdad con valores de texto\n",
    "\n",
    "### Operadores de comparaci√≥n en query():\n",
    "- == - Igual a\n",
    "- != - Diferente de  \n",
    "- '> - Mayor que\n",
    "- < - Menor que\n",
    "- '>= - Mayor o igual que\n",
    "- <= - Menor o igual que\n",
    "\n",
    "### Operadores l√≥gicos en query():\n",
    "- and - Operador l√≥gico Y para combinar condiciones\n",
    "- or - Operador l√≥gico O para alternativas\n",
    "- not - Operador l√≥gico NO para negaci√≥n\n",
    "- & - Operador alternativo para AND\n",
    "- | - Operador alternativo para OR\n",
    "\n",
    "### Variables externas en query():\n",
    "- @ - S√≠mbolo para referenciar variables externas de Python\n",
    "- .query('@variable') - Usa una variable externa en la consulta\n",
    "\n",
    "### M√©todos de cadena en query():\n",
    "- .str.contains() - Busca patrones dentro de strings\n",
    "- .str.startswith() - Filtra strings que empiecen con un patr√≥n\n",
    "- .str.endswith() - Filtra strings que terminen con un patr√≥n\n",
    "- .isin() - Verifica si los valores est√°n en una lista espec√≠fica\n",
    "\n",
    "### Funci√≥n de salida:\n",
    "- print() - Muestra los resultados del filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0914ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Filtrado simple con query():\n",
    "df_filtered = df.query('age > 25')\n",
    "\n",
    "# Filtrado con m√∫ltiples condiciones:\n",
    "df_filtered = df.query('age > 25 and salary < 50000')\n",
    "\n",
    "# Filtrado usando variables externas:\n",
    "min_age = 30\n",
    "df_filtered = df.query('age > @min_age')\n",
    "\n",
    "# Filtrado con operadores de cadena:\n",
    "df_filtered = df.query('name.str.contains(\"John\")')\n",
    "\n",
    "# Filtrado con listas usando isin():\n",
    "cities = ['Madrid', 'Barcelona', 'Valencia']\n",
    "df_filtered = df.query('city.isin(@cities)')\n",
    "\n",
    "# Filtrado con negaci√≥n:\n",
    "df_filtered = df.query('not (age < 18)')\n",
    "\n",
    "# Filtrado combinando condiciones complejas:\n",
    "df_filtered = df.query('(age >= 25 and age <= 65) and salary > 30000')\n",
    "\n",
    "# Filtrado con valores nulos:\n",
    "df_filtered = df.query('column.notna()')\n",
    "\n",
    "# Filtrado con rangos usando between():\n",
    "df_filtered = df.query('age.between(25, 65)')\n",
    "\n",
    "# Filtrado case-sensitive en strings:\n",
    "df_filtered = df.query('name.str.contains(\"john\", case=False)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb8e8ac",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Sintaxis de expresiones\n",
    "- Usar cadenas de texto para definir condiciones de filtrado de manera intuitiva\n",
    "- Operadores de comparaci√≥n\n",
    "- Aplicar >, <, ==, !=, >=, <= dentro de expresiones query()\n",
    "- Operadores l√≥gicos\n",
    "- Combinar m√∫ltiples condiciones usando and, or, not para filtros complejos\n",
    "- Variables externas\n",
    "- Referenciar variables de Python usando @ para hacer consultas din√°micas\n",
    "- M√©todos de cadena integrados\n",
    "- Usar .str.contains(), .str.startswith(), .str.endswith() dentro de query()\n",
    "- Filtrado por listas\n",
    "- Utilizar .isin() para verificar pertenencia a conjuntos de valores\n",
    "- Manejo de valores nulos\n",
    "- Aplicar .notna() y .isna() para filtrar datos faltantes\n",
    "- Rangos de valores\n",
    "- Usar .between() para filtrar valores dentro de un rango espec√≠fico\n",
    "- Case sensitivity\n",
    "- Controlar la sensibilidad a may√∫sculas/min√∫sculas en filtros de texto\n",
    "- Optimizaci√≥n de rendimiento\n",
    "- Aprovechar la eficiencia del motor de consultas de pandas\n",
    "- Legibilidad del c√≥digo\n",
    "- Crear filtros m√°s legibles comparado con indexaci√≥n booleana tradicional\n",
    "- Expresiones complejas\n",
    "- Construir consultas sofisticadas combinando m√∫ltiples operadores y condiciones\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øEn qu√© situaciones ser√≠a m√°s ventajoso usar el m√©todo query() en lugar de la indexaci√≥n booleana tradicional, y c√≥mo puede el uso de variables externas con @ hacer tus consultas m√°s din√°micas y reutilizables?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd77673",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Uso de estructuras de datos externas para filtrar DataFrames\n",
    "Este cap√≠tulo introduce el uso de estructuras de datos externas como listas, sets, diccionarios y otros DataFrames para filtrar y seleccionar datos de manera eficiente. Se enfoca en:\n",
    "\n",
    "- Filtrado con listas y arrays\n",
    "    - Utilizar listas de Python y arrays de NumPy como criterios de filtrado para seleccionar registros espec√≠ficos\n",
    "- Filtrado con sets para optimizaci√≥n\n",
    "    - Aprovechar la eficiencia de los sets para filtros de pertenencia en datasets grandes\n",
    "- Uso del m√©todo isin()\n",
    "    - Aplicar el m√©todo isin() para verificar si los valores de una columna est√°n presentes en una estructura externa\n",
    "- Filtrado con diccionarios\n",
    "    - Usar diccionarios como mapas de filtrado para condiciones m√°s complejas y transformaciones simult√°neas\n",
    "- Combinaci√≥n de DataFrames para filtrado\n",
    "    - Utilizar merge() y join() para filtrar un DataFrame bas√°ndose en los datos de otro DataFrame\n",
    "- Filtrado con Series externas\n",
    "    - Emplear Series de pandas como m√°scaras booleanas para filtrado avanzado\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "### Importaci√≥n de librer√≠as:\n",
    "- import pandas as pd - Importa la librer√≠a pandas para manipulaci√≥n de datos\n",
    "- import numpy as np - Importa NumPy para operaciones con arrays\n",
    "\n",
    "### Carga de datos:\n",
    "- pd.read_csv() - Lee archivos CSV y carga los datos en un DataFrame\n",
    "\n",
    "### M√©todos de filtrado con estructuras externas:\n",
    "- .isin() - Verifica si los valores est√°n presentes en una lista, set o array\n",
    "- .isin(lista) - Filtra usando una lista de Python\n",
    "- .isin(set) - Filtra usando un set de Python para mayor eficiencia\n",
    "- .isin(array) - Filtra usando un array de NumPy\n",
    "\n",
    "### Operadores de negaci√≥n:\n",
    "- ~ - Operador de negaci√≥n para invertir condiciones booleanas\n",
    "- ~df['columna'].isin(lista) - Filtra valores que NO est√°n en la lista\n",
    "\n",
    "### M√©todos de combinaci√≥n para filtrado:\n",
    "- pd.merge() - Combina DataFrames y puede usarse para filtrado\n",
    "- .merge(df2, on='columna') - Combina DataFrames en una columna com√∫n\n",
    "- .merge(df2, how='inner') - Realiza inner join manteniendo solo coincidencias\n",
    "- .merge(df2, how='left') - Realiza left join manteniendo todas las filas del DataFrame izquierdo\n",
    "\n",
    "### M√©todos de join:\n",
    "- .join() - Une DataFrames por sus √≠ndices\n",
    "- .join(df2, how='inner') - Join interno manteniendo solo coincidencias de √≠ndices\n",
    "\n",
    "### Creaci√≥n de estructuras de filtrado:\n",
    "- list() - Crea listas de Python para filtrado\n",
    "- set() - Crea sets de Python para filtrado eficiente\n",
    "- dict() - Crea diccionarios para mapeo y filtrado\n",
    "\n",
    "### M√©todos de conversi√≥n:\n",
    "- .tolist() - Convierte Series o arrays a listas de Python\n",
    "- .unique() - Obtiene valores √∫nicos para crear estructuras de filtrado\n",
    "- .values - Obtiene los valores como array de NumPy\n",
    "\n",
    "### Funci√≥n de salida:\n",
    "- print() - Muestra los resultados del filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c59eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Filtrado con lista:\n",
    "ciudades_objetivo = ['Madrid', 'Barcelona', 'Valencia']\n",
    "df_filtrado = df[df['ciudad'].isin(ciudades_objetivo)]\n",
    "\n",
    "# Filtrado con set para mejor rendimiento:\n",
    "ids_validos = {1, 2, 3, 5, 8, 13}\n",
    "df_filtrado = df[df['id'].isin(ids_validos)]\n",
    "\n",
    "# Filtrado con negaci√≥n:\n",
    "generos_excluir = ['Terror', 'Suspenso']\n",
    "df_filtrado = df[~df['genero'].isin(generos_excluir)]\n",
    "\n",
    "# Filtrado usando otro DataFrame:\n",
    "df_clientes_vip = pd.DataFrame({'cliente_id': [101, 102, 105]})\n",
    "df_filtrado = df.merge(df_clientes_vip, on='cliente_id', how='inner')\n",
    "\n",
    "# Filtrado con diccionario:\n",
    "categorias_validas = {'A': 'Premium', 'B': 'Standard', 'C': 'Basic'}\n",
    "df_filtrado = df[df['categoria'].isin(categorias_validas.keys())]\n",
    "\n",
    "# Filtrado con Series externa:\n",
    "productos_populares = df_ventas.groupby('producto')['cantidad'].sum()\n",
    "top_productos = productos_populares.nlargest(5).index\n",
    "df_filtrado = df[df['producto'].isin(top_productos)]\n",
    "\n",
    "# Combinaci√≥n con query():\n",
    "regiones_objetivo = ['Norte', 'Sur']\n",
    "df_filtrado = df.query(\"region in @regiones_objetivo and ventas > 1000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a2644d",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Estructuras externas\n",
    "- Listas, sets, diccionarios, arrays y otros DataFrames usados como criterios de filtrado\n",
    "- M√©todo isin()\n",
    "- Funci√≥n principal para verificar pertenencia de valores en estructuras externas\n",
    "- Optimizaci√≥n con sets\n",
    "- Usar sets en lugar de listas para mejorar rendimiento en filtros grandes\n",
    "- Operador de negaci√≥n (~)\n",
    "- Invertir condiciones de filtrado para excluir valores\n",
    "- Merge para filtrado\n",
    "- Usar combinaciones de DataFrames como t√©cnica de filtrado avanzada\n",
    "- Variables externas en query()\n",
    "- Referenciar estructuras externas usando @ en strings de consulta\n",
    "- Filtrado din√°mico\n",
    "- Crear filtros que cambian seg√∫n datos externos o c√°lculos previos\n",
    "- Reutilizaci√≥n de criterios\n",
    "- Definir una vez las estructuras de filtrado y reutilizarlas m√∫ltiples veces\n",
    "- Eficiencia de memoria\n",
    "- Considerar el tama√±o de las estructuras externas para optimizar el rendimiento\n",
    "- Combinaci√≥n de condiciones\n",
    "- Usar estructuras externas junto con otras condiciones l√≥gicas\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øEn qu√© situaciones ser√≠a m√°s eficiente usar un set en lugar de una lista para filtrar un DataFrame con millones de registros, y c√≥mo determinar√≠as cu√°ndo es apropiado usar merge() versus isin() para filtrar bas√°ndose en datos de otro DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b76d48",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Filtrado por condiciones m√∫ltiples\n",
    "Este cap√≠tulo introduce el filtrado avanzado de DataFrames usando m√∫ltiples condiciones simult√°neas, una t√©cnica esencial para an√°lisis de datos complejos y selecci√≥n precisa de registros. Se enfoca en:\n",
    "\n",
    "- Operadores l√≥gicos para combinaci√≥n de condiciones\n",
    "    - Utilizar operadores AND (&), OR (|) y NOT (~) para crear filtros complejos con m√∫ltiples criterios\n",
    "- Filtrado con condiciones num√©ricas m√∫ltiples\n",
    "    - Aplicar rangos, comparaciones y condiciones matem√°ticas combinadas para seleccionar datos espec√≠ficos\n",
    "- Filtrado con condiciones categ√≥ricas m√∫ltiples\n",
    "    - Combinar filtros de texto, categor√≠as y valores discretos usando operadores l√≥gicos\n",
    "- Uso del m√©todo query() para condiciones complejas\n",
    "    - Emplear query() con sintaxis SQL-like para escribir filtros m√∫ltiples de manera m√°s legible\n",
    "- Agrupaci√≥n de condiciones con par√©ntesis\n",
    "    - Controlar la precedencia de operadores usando par√©ntesis para crear l√≥gica de filtrado precisa\n",
    "- Filtrado con variables externas\n",
    "    - Referenciar variables Python en filtros usando el s√≠mbolo @ en query()\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "### Importaci√≥n de librer√≠as:\n",
    "- import pandas as pd - Importa la librer√≠a pandas para manipulaci√≥n de datos\n",
    "\n",
    "### Carga de datos:\n",
    "- pd.read_csv() - Lee archivos CSV y carga los datos en un DataFrame\n",
    "\n",
    "### Operadores l√≥gicos para filtrado:\n",
    "- & - Operador AND para combinar condiciones (ambas deben ser verdaderas)\n",
    "- | - Operador OR para alternativas (al menos una debe ser verdadera)\n",
    "- ~ - Operador NOT para negar condiciones (invierte True/False)\n",
    "\n",
    "### Operadores de comparaci√≥n:\n",
    "- == - Igual a\n",
    "- != - Diferente de\n",
    "- '> - Mayor que\n",
    "- < - Menor que\n",
    "- '>= - Mayor o igual que\n",
    "- <= - Menor o igual que\n",
    "\n",
    "### M√©todo query() para filtrado avanzado:\n",
    "- .query() - Permite filtrado usando strings con sintaxis SQL-like\n",
    "- .query(\"condicion1 and condicion2\") - Combina condiciones con AND\n",
    "- .query(\"condicion1 or condicion2\") - Combina condiciones con OR\n",
    "- .query(\"not condicion\") - Niega una condici√≥n\n",
    "- .query(\"@variable\") - Referencia variables externas\n",
    "\n",
    "### M√©todos de filtrado con texto:\n",
    "- .str.contains() - Busca patrones de texto en columnas string\n",
    "- .str.startswith() - Filtra strings que empiezan con un patr√≥n\n",
    "- .str.endswith() - Filtra strings que terminan con un patr√≥n\n",
    "- .isin() - Verifica si valores est√°n en una lista\n",
    "\n",
    "### M√©todos de informaci√≥n:\n",
    "- .shape - Muestra dimensiones del DataFrame filtrado\n",
    "- .info() - Informaci√≥n general del DataFrame\n",
    "- .describe() - Estad√≠sticas descriptivas de datos num√©ricos\n",
    "\n",
    "### Funci√≥n de salida:\n",
    "- print() - Muestra resultados del filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5105e396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Filtrado con m√∫ltiples condiciones num√©ricas:\n",
    "# Filtrar por edad y salario\n",
    "df_filtrado = df[(df['edad'] >= 25) & (df['edad'] <= 65) & (df['salario'] > 50000)]\n",
    "\n",
    "# Filtrado con condiciones categ√≥ricas m√∫ltiples:\n",
    "# Filtrar por departamento y estado\n",
    "df_filtrado = df[(df['departamento'] == 'Ventas') | (df['departamento'] == 'Marketing')] & (df['activo'] == True)\n",
    "\n",
    "# Filtrado con negaci√≥n:\n",
    "# Excluir ciertos valores\n",
    "df_filtrado = df[~(df['categoria'] == 'Descontinuado') & (df['precio'] > 0)]\n",
    "\n",
    "# Uso de query() con m√∫ltiples condiciones:\n",
    "# Filtrado usando query() - m√°s legible\n",
    "df_filtrado = df.query(\"edad >= 25 and edad <= 65 and salario > 50000\")\n",
    "\n",
    "# Filtrado con variables externas usando query():\n",
    "edad_minima = 25\n",
    "edad_maxima = 65\n",
    "salario_minimo = 50000\n",
    "df_filtrado = df.query(\"edad >= @edad_minima and edad <= @edad_maxima and salario > @salario_minimo\")\n",
    "\n",
    "# Filtrado con rangos usando between():\n",
    "# Filtrar usando rangos\n",
    "df_filtrado = df[df['fecha'].between('2020-01-01', '2020-12-31') & (df['ventas'] > 1000)]\n",
    "\n",
    "# Combinaci√≥n de filtros de texto y num√©ricos:\n",
    "# Filtrar productos espec√≠ficos con condiciones de precio\n",
    "df_filtrado = df[(df['producto'].str.contains('iPhone')) & (df['precio'] >= 500) & (df['stock'] > 0)]\n",
    "\n",
    "# Filtrado con m√∫ltiples valores usando isin():\n",
    "# Filtrar m√∫ltiples categor√≠as con condici√≥n adicional\n",
    "categorias = ['Electr√≥nicos', 'Ropa', 'Hogar']\n",
    "df_filtrado = df[df['categoria'].isin(categorias) & (df['descuento'] > 0.1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc1be34",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Operadores bit a bit\n",
    "- Usar &, |, ~ en lugar de and, or, not para operaciones con DataFrames\n",
    "- Precedencia de operadores\n",
    "- Importancia de usar par√©ntesis para controlar el orden de evaluaci√≥n\n",
    "- Filtrado por rangos\n",
    "- Combinar condiciones >= y <= para seleccionar valores dentro de un rango\n",
    "- M√©todo query()\n",
    "- Alternativa m√°s legible usando sintaxis similar a SQL para filtros complejos\n",
    "- Variables externas en query()\n",
    "- Usar @ para referenciar variables Python dentro de strings de consulta\n",
    "- Combinaci√≥n de tipos de datos\n",
    "- Filtrar simult√°neamente por columnas num√©ricas, categ√≥ricas y de texto\n",
    "- Negaci√≥n de condiciones\n",
    "- Usar ~ para excluir registros que cumplan ciertas condiciones\n",
    "- Filtros din√°micos\n",
    "- Crear filtros que cambien seg√∫n variables definidas externamente\n",
    "- Optimizaci√≥n de consultas\n",
    "- Escribir filtros eficientes que minimicen el procesamiento de datos\n",
    "- Legibilidad del c√≥digo\n",
    "- Elegir entre sintaxis de corchetes o query() seg√∫n la complejidad del filtro\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øEn qu√© situaciones ser√≠a m√°s apropiado usar el m√©todo query() en lugar de la sintaxis tradicional con corchetes y operadores bit a bit, y c√≥mo determinar√≠as la mejor estrategia para combinar m√∫ltiples condiciones cuando trabajas con datasets de gran tama√±o?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ae481b",
   "metadata": {},
   "source": [
    "# üìñ Resumen del cap√≠tulo: Reemplazo de valores con where()\n",
    "Este cap√≠tulo introduce el m√©todo where() de pandas, una herramienta poderosa para el reemplazo condicional de valores en DataFrames y Series. Se enfoca en:\n",
    "\n",
    "- Reemplazo condicional b√°sico\n",
    "    - Utilizar where() para mantener valores que cumplen una condici√≥n y reemplazar los que no la cumplen\n",
    "- Combinaci√≥n con condiciones m√∫ltiples\n",
    "    - Aplicar where() con operadores l√≥gicos para crear transformaciones complejas basadas en m√∫ltiples criterios\n",
    "- Reemplazo con valores calculados\n",
    "    - Usar where() para reemplazar valores con c√°lculos din√°micos o valores derivados de otras columnas\n",
    "- Preservaci√≥n selectiva de datos\n",
    "    - Mantener valores originales cuando cumplen condiciones espec√≠ficas y modificar solo los que requieren cambios\n",
    "- Transformaci√≥n de columnas completas\n",
    "    - Aplicar where() a columnas enteras para crear nuevas versiones transformadas de los datos\n",
    "- Manejo de valores faltantes\n",
    "    - Usar where() en combinaci√≥n con estrategias para manejar NaN y valores nulos durante el reemplazo\n",
    "\n",
    "# üìã Listado completo de comandos utilizados:\n",
    "### Importaci√≥n de librer√≠as:\n",
    "- import pandas as pd - Importa la librer√≠a pandas para manipulaci√≥n de datos\n",
    "- import numpy as np - Importa NumPy para operaciones num√©ricas y manejo de NaN\n",
    "\n",
    "### Carga de datos:\n",
    "- pd.read_csv() - Lee archivos CSV y carga los datos en un DataFrame\n",
    "\n",
    "### M√©todo where() principal:\n",
    "- .where() - Reemplaza valores que no cumplen una condici√≥n\n",
    "- .where(condicion) - Mantiene valores donde la condici√≥n es True, reemplaza con NaN donde es False\n",
    "- .where(condicion, otro_valor) - Mantiene valores donde la condici√≥n es True, reemplaza con otro_valor donde es False\n",
    "- .where(condicion, other=valor) - Sintaxis alternativa usando el par√°metro other\n",
    "\n",
    "### Operadores de comparaci√≥n para condiciones:\n",
    "- == - Igual a\n",
    "- != - Diferente de\n",
    "- '> - Mayor que\n",
    "- < - Menor que\n",
    "- '>= - Mayor o igual que\n",
    "- <= - Menor o igual que\n",
    "\n",
    "### Operadores l√≥gicos:\n",
    "- & - AND l√≥gico para combinar condiciones\n",
    "- | - OR l√≥gico para alternativas\n",
    "- ~ - NOT l√≥gico para negar condiciones\n",
    "\n",
    "### M√©todos complementarios:\n",
    "- .mask() - M√©todo inverso a where() (reemplaza donde la condici√≥n es True)\n",
    "- .fillna() - Rellena valores NaN resultantes de where()\n",
    "- .isna() - Identifica valores faltantes\n",
    "- .notna() - Identifica valores no faltantes\n",
    "\n",
    "### Funciones de NumPy:\n",
    "- np.nan - Representa valores faltantes\n",
    "- np.where() - Versi√≥n de NumPy para arrays (alternativa)\n",
    "\n",
    "### M√©todos de informaci√≥n:\n",
    "- .shape - Dimensiones del DataFrame\n",
    "- .info() - Informaci√≥n general del DataFrame\n",
    "- .describe() - Estad√≠sticas descriptivas\n",
    "\n",
    "### Funci√≥n de salida:\n",
    "- print() - Muestra resultados de las transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4df0117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de uso mostrados:\n",
    "\n",
    "# Reemplazo b√°sico con where():\n",
    "# Mantener valores mayores a 100, reemplazar otros con 0\n",
    "df['ventas_ajustadas'] = df['ventas'].where(df['ventas'] > 100, 0)\n",
    "\n",
    "# Reemplazo con condiciones m√∫ltiples:\n",
    "# Mantener valores en rango espec√≠fico\n",
    "df['precio_valido'] = df['precio'].where((df['precio'] >= 10) & (df['precio'] <= 1000), np.nan)\n",
    "\n",
    "# Reemplazo con valores calculados:\n",
    "# Reemplazar valores negativos con el promedio de la columna\n",
    "promedio = df['balance'].mean()\n",
    "df['balance_corregido'] = df['balance'].where(df['balance'] >= 0, promedio)\n",
    "\n",
    "# Uso de mask() como alternativa:\n",
    "# mask() es el inverso de where()\n",
    "df['descuento_aplicado'] = df['descuento'].mask(df['descuento'] > 0.5, 0.5)\n",
    "\n",
    "# Reemplazo basado en otra columna:\n",
    "# Reemplazar precios seg√∫n categor√≠a\n",
    "df['precio_final'] = df['precio'].where(df['categoria'] != 'Premium', df['precio'] * 1.2)\n",
    "\n",
    "# Combinaci√≥n con fillna():\n",
    "# Usar where() y luego rellenar NaN\n",
    "df['edad_valida'] = df['edad'].where(df['edad'] <= 100).fillna(df['edad'].median())\n",
    "\n",
    "# Reemplazo con strings:\n",
    "# Reemplazar valores de texto seg√∫n condici√≥n\n",
    "df['estado_cliente'] = df['estado'].where(df['compras'] > 5, 'Inactivo')\n",
    "\n",
    "# Uso de np.where() como alternativa:\n",
    "# Usando NumPy where para mayor flexibilidad\n",
    "df['categoria_edad'] = np.where(df['edad'] < 30, 'Joven', \n",
    "                       np.where(df['edad'] < 60, 'Adulto', 'Senior'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3804e440",
   "metadata": {},
   "source": [
    "### Conceptos clave cubiertos:\n",
    "- Reemplazo condicional\n",
    "- Mantener valores que cumplen condiciones y reemplazar los que no\n",
    "- M√©todo where()\n",
    "- Funci√≥n principal para reemplazo condicional en pandas\n",
    "- M√©todo mask()\n",
    "- Funci√≥n inversa a where() que reemplaza donde la condici√≥n es True\n",
    "- Par√°metro other\n",
    "- Valor de reemplazo cuando la condici√≥n es False\n",
    "- Preservaci√≥n selectiva\n",
    "- Mantener datos originales solo cuando cumplen criterios espec√≠ficos\n",
    "- Valores por defecto\n",
    "- Usar NaN como valor predeterminado cuando no se especifica reemplazo\n",
    "- Condiciones complejas\n",
    "- Combinar m√∫ltiples criterios usando operadores l√≥gicos\n",
    "- Transformaci√≥n in-place\n",
    "- Aplicar cambios directamente a columnas existentes o crear nuevas\n",
    "- Compatibilidad con NumPy\n",
    "- Usar np.where() para casos m√°s complejos con m√∫ltiples condiciones\n",
    "- Manejo de tipos de datos\n",
    "- Considerar la compatibilidad de tipos entre valores originales y de reemplazo\n",
    "- Cadena de transformaciones\n",
    "- Combinar where() con otros m√©todos como fillna() para flujos completos\n",
    "- Eficiencia de memoria\n",
    "- Optimizar el uso de where() para datasets grandes\n",
    "\n",
    "## ü§î Pregunta para reflexionar:\n",
    "¬øEn qu√© situaciones ser√≠a m√°s apropiado usar where() versus mask(), y c√≥mo determinar√≠as la mejor estrategia para manejar los valores NaN que pueden resultar del uso de where() sin especificar un valor de reemplazo?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
